<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>MyCoon</title>
    <description>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.
</description>
    <link>/</link>
    <atom:link href="/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sun, 30 Oct 2016 12:16:28 -0400</pubDate>
    <lastBuildDate>Sun, 30 Oct 2016 12:16:28 -0400</lastBuildDate>
    <generator>Jekyll v3.2.1</generator>
    
      <item>
        <title>CSP</title>
        <description>&lt;h2&gt;Content&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Constraint Satisfaction Problems (Backtracking Search) Overview

&lt;ol&gt;
&lt;li&gt;CSP v.s Traditional Search Problems&lt;/li&gt;
&lt;li&gt;Feature Vectors&lt;/li&gt;
&lt;li&gt;Constraint Graph&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;Solving CSPs

&lt;ol&gt;
&lt;li&gt;Viewing CSP as Search Problem&lt;/li&gt;
&lt;li&gt;Backtracking Search Algorithm&lt;/li&gt;
&lt;li&gt;Constraint Propagation

&lt;ol&gt;
&lt;li&gt;Forward Checking&lt;/li&gt;
&lt;li&gt;Generalizaed Arc Consistency&lt;/li&gt;
&lt;li&gt;Heuristics&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;!--more--&gt;

&lt;hr&gt;

&lt;h2&gt;Constraint Satisfaction Problems (Backtracking Search) Overview&lt;/h2&gt;

&lt;h3&gt;CSP v.s Traditional Search Problems&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;CSP does not care about the &lt;em&gt;sequence of moves&lt;/em&gt; to reach goal state&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;Feature Vectors&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Represent states as &lt;strong&gt;vectors of feature values&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Formalization

&lt;ul&gt;
&lt;li&gt;A set of &lt;strong&gt;features/variables&lt;/strong&gt; &lt;code&gt;V1, ... Vn&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Domain&lt;/strong&gt; for each variable &lt;code&gt;Dom[Vi]&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;A set of &lt;strong&gt;constraints&lt;/strong&gt; &lt;code&gt;C1, ..., Cm&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Scope&lt;/strong&gt;: a set of variables it operates over&lt;/li&gt;
&lt;li&gt;Unary, binary, higher-order constraints&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;State&lt;/strong&gt;: assignment of value for each variable&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Partial state&lt;/strong&gt;: assignment of value for some variables&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Goal state&lt;/strong&gt;: a state satisfying all &lt;strong&gt;constraints&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;Constraint Graph&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Nodes: &lt;strong&gt;variables&lt;/strong&gt;; arcs: &lt;strong&gt;constraints&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Solving CSPs&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Search through the space of partial assignments&lt;/li&gt;
&lt;li&gt;Order of assignments does not matter&lt;/li&gt;
&lt;li&gt;If we falsify a constraint, we immediately reject the current partial assignment&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;Viewing CSP as Search Problem&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Initial state&lt;/strong&gt;: empty assignment&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Successor function&lt;/strong&gt;: a value assigned to any unassigned variable s.t. no constraints return false&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Goal test&lt;/strong&gt;: complete assignment&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;Backtracking Search Algorithm&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Similar to DFS&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;BT(Level):
    If all variables assigned:
        PRINT Value of each Variable
        RETURN

    V := PickUnassignedVariable()
    Assigned[V] := TRUE
    for d := each member of Domain(V):
        Value[V] := d
        ConstraintsOK = TRUE
        for each constraint C such that
            a) V is a variable of C and
            b) all other variables of C are assigned: 
            If C is not satisfied by the set of current assignments:
                ConstraintsOK = FALSE
                break
        If ConstraintsOk == TRUE:
            BT(Level+1)
    Assigned[V] := FALSE //UNDO as we have tried all of V’s values return
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;Constraint Propagation&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Look ahead&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;Forward Checking&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;When instantiating a variable, check all constrants with &lt;strong&gt;only one ininstantiated variable&lt;/strong&gt; remaining&lt;/li&gt;
&lt;li&gt;Prune values of that variable that violate the constraint&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Algorithm&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;FCCheck(C,x):
    // C is a constraint with all its variables already assigned, except for variable x

    for d := each member of CurDom[x]:
        If making x = d together with previous assignments
    to variables in scope C falsifies C:
            remove d from CurDom[x]

    If CurDom[x] = {}:
        return DWO (Domain Wipe Out)
    Else:
        return ok

FC(Level):
    If all variables assigned:
        PRINT Value of each Variable
        RETURN

    V := PickAnUnassignedVariable()
    Assigned[V] := TRUE
    for d := each member of CurDom(V):
        Value[V] := d
        DWOoccured:= False
        for each constraint C over V such that
            a) C has only one unassigned variable X in its scope:
            If (FCCheck(C,X) == DWO):
                DWOoccurred:= True
                break
        If(not DWOoccured)
            FC(Level+1)
        RestoreAllValuesPrunedByFCCheck()
    Assigned[V] := FALSE
    return;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;Generalizaed Arc Consistency&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;C(V1, ..., Vn)&lt;/code&gt; is GAC with regard to &lt;code&gt;Vi&lt;/code&gt; iff for every value of &lt;code&gt;Vi&lt;/code&gt;, there exist values of &lt;code&gt;V1, ..., Vn&lt;/code&gt; that satisfy C&lt;/li&gt;
&lt;li&gt;If for &lt;code&gt;Vi = d&lt;/code&gt; is not consistent wrt the constraint, &lt;code&gt;d&lt;/code&gt; is &lt;strong&gt;arc inconsistent&lt;/strong&gt; and can be removed from domain of &lt;code&gt;Vi&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;A constraint that is GAC may become non-GAC due to pruning of domain values during search&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Algorithm&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;GAC_Enforce():
// GAC-Queue contains all constraints one of whose variables has had its domain reduced

while GACQueue not empty:
    C = GACQueue.extract()
    for V := each member of scope(C):
        for d := CurDom[V]:
            Find an assignment A for all other variables in scope(C) such that C(A ∪ V=d) = True
            if A not found:
                CurDom[V] = CurDom[V] – d 
            if CurDom[V] = ∅:
                empty GACQueue
                return DWO
            else:
                push all constraints C’ s.t. V ∈ scope(C’) and C’ !∈ GACQueue on to GACQueue
return TRUE

GAC(Level):
    If all variables are assigned:
        PRINT Value of each Variable
        RETURN

    V := PickAnUnassignedVariable()
    Assigned[V] := TRUE
    for d := each member of CurDom(V):
        Value[V] := d
        Prune all values of V != d from CurDom[V]
        for each constraint C whose scope contains V:
            Put C on GACQueue
        if(GAC_Enforce() != DWO):
            GAC(Level+1)
        RestoreAllValuesPrunedFromCurDoms()

    Assigned[V] := FALSE
    return;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;May keep track of &lt;strong&gt;supports&lt;/strong&gt; to avoid having to search through all possible assignments and check satisfication&lt;/li&gt;
&lt;li&gt;Check if current support still valie, i.e. all values it assigns still lie in the variables&amp;#39; current domains&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;Heuristics&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Ordering of variables

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Minimum Remaining Values (MRV)&lt;/strong&gt;: returns the variable with the most constrained current domain&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Degree Heuristic (DH)&lt;/strong&gt;: returns variable imposing the most constraints on remaining unassigned variables&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Ordering of values

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Least Constraining Value (LCV)&lt;/strong&gt;: the best value is the one ruling out the fewest domain values in other variables that share at least one constraint with var&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sun, 30 Oct 2016 00:00:00 -0400</pubDate>
        <link>/blog/notes/ai/2016/10/30/csp.html</link>
        <guid isPermaLink="true">/blog/notes/ai/2016/10/30/csp.html</guid>
        
        <category>AI</category>
        
        <category>CSC384</category>
        
        <category>CSP</category>
        
        
        <category>Blog</category>
        
        <category>Notes</category>
        
        <category>AI</category>
        
      </item>
    
      <item>
        <title>Search</title>
        <description>&lt;h2&gt;Content&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Search Overview

&lt;ol&gt;
&lt;li&gt;Formalism of Search&lt;/li&gt;
&lt;li&gt;Searching Template&lt;/li&gt;
&lt;li&gt;Critical Properties of Search&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;Uninformed Search

&lt;ol&gt;
&lt;li&gt;BFS&lt;/li&gt;
&lt;li&gt;DFS&lt;/li&gt;
&lt;li&gt;Depth Limited Search&lt;/li&gt;
&lt;li&gt;Iterative Deepening Search&lt;/li&gt;
&lt;li&gt;Uniform-Cost Search&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;Informed/Heuristic Search

&lt;ol&gt;
&lt;li&gt;Best First Search&lt;/li&gt;
&lt;li&gt;A*&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;!--more--&gt;

&lt;hr&gt;

&lt;h2&gt;Search Overview&lt;/h2&gt;

&lt;h3&gt;Formalism of Search&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;State space&lt;/li&gt;
&lt;li&gt;Initial state &amp;amp; goal state&lt;/li&gt;
&lt;li&gt;Actions/successor functions/state space transitions &lt;code&gt;S(x)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Costs &lt;code&gt;C(x, a, y)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Heuristics to guide search&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;h4&gt;Complex situations&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Actions lead to multiple states&lt;/li&gt;
&lt;li&gt;Unsure of a given state&lt;/li&gt;
&lt;li&gt;=&amp;gt; &lt;strong&gt;Probabilistic models&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h3&gt;Searching Template&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;State annotation

&lt;ul&gt;
&lt;li&gt;State + action, parent state, cost, ...&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Frontier&lt;/strong&gt;: states haven&amp;#39;t explored or expanded but want to explore&lt;/li&gt;
&lt;li&gt;Order of frontiers (selection rules) implies the type of search, e.g. &lt;code&gt;BFS&lt;/code&gt;, &lt;code&gt;DFS&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;TreeSearch(Frontier, Successors, Goal):
    If Frontier empty:
        return failure

    Curr = select state from Frontier
    If (Goal(Curr)):
        return Curr
    Frontier' = (Frontier - {Curr}) ∪ Successors(Curr)
    return TreeSearch(Frontier', Successors, Goal)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;Critical Properties of Search&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Completeness&lt;/li&gt;
&lt;li&gt;Optimality&lt;/li&gt;
&lt;li&gt;Time complexity&lt;/li&gt;
&lt;li&gt;Space complexity&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Uninformed Search&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Fixed rule for selecting next state&lt;/li&gt;
&lt;li&gt;Do not consider any &lt;strong&gt;domain specific information&lt;/strong&gt; about the particular search problem&lt;/li&gt;
&lt;li&gt;e.g. BFS, Uniform-Cost, DFS, Depth-Limited, Iterative-Deepening&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;Path &amp;amp; Cycle Checking&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Path checking

&lt;ul&gt;
&lt;li&gt;Ensure expanded state &lt;code&gt;c&lt;/code&gt; not equal to state reached by any ancestor of &lt;code&gt;c&lt;/code&gt; along this path&lt;/li&gt;
&lt;li&gt;Path checked in isolation&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Cycle checking/ Multiple path checking

&lt;ul&gt;
&lt;li&gt;Ensure &lt;code&gt;c&lt;/code&gt; not equal to any previously expanded state&lt;/li&gt;
&lt;li&gt;Space complexity of DFS goes &lt;code&gt;exponential&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Non-uniform costs have additional issues&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;BFS&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;O(b^(d+1))&lt;/code&gt; space: explored nodes + nodes expanded at goal level before reaching goal&lt;/li&gt;
&lt;li&gt;&lt;code&gt;O(b^(d+1))&lt;/code&gt; time

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;1 + b + b^2 +...+ b^d + b(b^d-1)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Optimal&lt;/li&gt;
&lt;li&gt;Complete&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;DFS&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;O(bm)&lt;/code&gt; space (one path at a time)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;O(b^m)&lt;/code&gt; time, &lt;code&gt;m&lt;/code&gt; = length of longest path in state space&lt;/li&gt;
&lt;li&gt;Complete for acyclic graph or cycles pruned&lt;/li&gt;
&lt;li&gt;Not optimal&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;Depth Limited Search&lt;/h3&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;DLS(Frontier, Successors, Goal):
    While Frontier not empty:
        n = first node from Frontier
        Curr = terminal state of n
        If (Goal(Curr)):
            return n

        If Depth &amp;lt; D: // limit Frontiers to depth D
            Frontier = (Frontier - {n}) ∪ Successors(Curr)
        Else:
            Frontier = Frontier - {n}
            CutOffOccured = TRUE
    return FAIL
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;Iterative Deepening Search&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Iteratively increase depth limit and perform DLS&lt;/li&gt;
&lt;li&gt;Stop if solution found OR DLS failed without cutting off any nodes&lt;/li&gt;
&lt;li&gt;Not good if many cycles&lt;/li&gt;
&lt;li&gt;&lt;code&gt;O(bd)&lt;/code&gt; space&lt;/li&gt;
&lt;li&gt;&lt;code&gt;O(b^d)&lt;/code&gt; time

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;(d+1)b^0 + db + ... + b^d&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Complete&lt;/li&gt;
&lt;li&gt;Optimal if costs uniform

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Cost bound&lt;/strong&gt; for non-uniform costs&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;Uniform-Cost Search&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Frontier&lt;/code&gt; ordered by &lt;strong&gt;increasing cost of path&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Nodes rejected or replaced on Frontier guaranteed to have more costly paths&lt;/li&gt;
&lt;li&gt;&lt;code&gt;O(b^(C*/ε))&lt;/code&gt; time &amp;amp; space, &lt;code&gt;C*&lt;/code&gt; = cost of optimal solution&lt;/li&gt;
&lt;li&gt;Complete if positive, nonzero transition costs&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Optimal&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;Given: each transition has costs &amp;gt;= ε &amp;gt; 0

Lemma 1: If n2 is expanded immediately after n1, then c(n1) &amp;lt;= c(n2)
Lemma 2: When node n is expanded, every path in the search space with cost &amp;lt; c(n) has already been expanded
Lemma 3: The first time USC expandes a node n terminating at state S, it has found the minimal cost path to S
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Informed/Heuristic Search&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;h(n1) &amp;lt; h(n2)&lt;/code&gt; if we guess it&amp;#39;s cheaper to get to goal from n1 than from n2&lt;/li&gt;
&lt;li&gt;&lt;code&gt;h(n) = 0&lt;/code&gt; for goal nodes n&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;Best First Search&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Only use &lt;code&gt;h(n)&lt;/code&gt; to guide the search&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;A*&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;f(n) = g(n) + h(n)&lt;/code&gt;, &lt;code&gt;g(n)&lt;/code&gt; = cost of path to n&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Adimissible h(n)&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;Let &lt;code&gt;h*(n)&lt;/code&gt; be the cost of an optimal path from n to goal node, then &lt;strong&gt;admissible heuristic&lt;/strong&gt; satisfies:&lt;br&gt;
&lt;code&gt;h(n) &amp;lt;= h*(n)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Never &lt;strong&gt;over-estimates&lt;/strong&gt; the cost to reach goal, won&amp;#39;t miss any promising paths&lt;/li&gt;
&lt;li&gt;Implies &lt;strong&gt;optimality&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Monotonic/Consistent h(n)&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Local admissibility&lt;/li&gt;
&lt;li&gt;&lt;code&gt;h(n1) &amp;lt;= c(n1, a, n2) + h(n2)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Consistency -&amp;gt; Adimissibility&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;Assume h(n1) &amp;lt;= c(n1, a, n2) + h(n2)
Prove h(n) &amp;lt;= h*(n)

If not path from n to goal, then h*(n) = inf
Else
    Let n-&amp;gt;n1-&amp;gt;...-&amp;gt;n* be an optimal path from n to goal
    (Cost: h*(n); cost of sub-path: h*(ni))

    Base case: n = n*, h(n) = 0 &amp;lt;= h*(n) = 0
    Induction: h(n1) &amp;lt;= h*(n1)
        h(n) &amp;lt;= c(n, a1, n1) + h(n1) &amp;lt;= c(n, a1, n1) + h*(n1) = h*(n)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;f(n)&lt;/code&gt; non-decreasing&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;f(n1) = g(n1) + h(n1) &amp;lt;= g(n1) + c(n1, a, n2) + h(n2) = f(n2)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;f(n1) &amp;lt;= f(n2)&lt;/code&gt; if n2 expanded after n1&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If n has been expanded, every path with lower f-value has already been expanded&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The first time A* expands a node, it has found the min cost path to that node&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Admissible &amp;amp; monotonic h(n)&lt;/strong&gt; =&amp;gt; Optimal&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Same time &amp;amp; space bounds as UCS

&lt;ul&gt;
&lt;li&gt;# of nodes expanded no larger than UCS&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Complete

&lt;ul&gt;
&lt;li&gt;Finite # of paths having &lt;code&gt;f-value &amp;lt; c(SolutionPath)&lt;/code&gt;, since each action has &lt;code&gt;costs &amp;gt;= ε &amp;gt; 0&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Optimal&lt;/li&gt;
&lt;li&gt;Cycle checking: keep only the first path to a state, rejecting all subsequent paths&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Admissibility without monotonicity&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Optimal

&lt;ul&gt;
&lt;li&gt;But ordering of nodes not guaranteed optimal when put in queue&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Cycle checking: keep revisited nodes with cost less than before&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Expand less state space, but still constrained by speed or memory&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;IDA*: reduce memory requirements

&lt;ul&gt;
&lt;li&gt;Cutoff: &lt;code&gt;f-value&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;curBound&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;smallestNotExplored&lt;/code&gt;: smallest &lt;code&gt;f-value&lt;/code&gt; of discarded nodes in a round

&lt;ul&gt;
&lt;li&gt;Expand all nodes with &lt;code&gt;f-value&lt;/code&gt; equal to &lt;code&gt;f-limit&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Weighted A*

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;f(n) = (1-ε) * g(n) + ε * h(n)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Anytime A*

&lt;ul&gt;
&lt;li&gt;Find the best path for a given ε&lt;/li&gt;
&lt;li&gt;Reduce ε and replan&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sat, 29 Oct 2016 00:00:00 -0400</pubDate>
        <link>/blog/notes/ai/2016/10/29/search.html</link>
        <guid isPermaLink="true">/blog/notes/ai/2016/10/29/search.html</guid>
        
        <category>AI</category>
        
        <category>CSC384</category>
        
        <category>search</category>
        
        
        <category>Blog</category>
        
        <category>Notes</category>
        
        <category>AI</category>
        
      </item>
    
      <item>
        <title>Game Tree Search</title>
        <description>&lt;h2&gt;Content&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Game Overview

&lt;ol&gt;
&lt;li&gt;Game Properties&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;Two-Player Zero-Sum Game

&lt;ol&gt;
&lt;li&gt;Definition&lt;/li&gt;
&lt;li&gt;Intuition&lt;/li&gt;
&lt;li&gt;MiniMax Strategy&lt;/li&gt;
&lt;li&gt;Real-Time/Online search&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;!--more--&gt;

&lt;hr&gt;

&lt;h2&gt;Game Overview&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Generalization of Search Problems

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Game tree&lt;/strong&gt;: actions of &amp;gt;= 1 players/agents&lt;/li&gt;
&lt;li&gt;Agents acting to &lt;strong&gt;maximize their profits&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Others&amp;#39; profits might not have positive effect on yours&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Key Features of Game

&lt;ul&gt;
&lt;li&gt;Each player has different goal&lt;/li&gt;
&lt;li&gt;Different paths/states assigned different costs&lt;/li&gt;
&lt;li&gt;Each player tries to alter the world to best benefit itself&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;Game Properties&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Two-player&lt;/li&gt;
&lt;li&gt;Discrete: game states or decision can be mapped on discrete values&lt;/li&gt;
&lt;li&gt;Finite: a finite # of states/decisions can be made&lt;/li&gt;
&lt;li&gt;Zero-sum (Fully Competitive): A gains = B loses

&lt;ul&gt;
&lt;li&gt;Strategic/normal form game: one shot e.g. rock-paper-scissors&lt;/li&gt;
&lt;li&gt;Extensive form game: turn-taking, multiple moves&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Deterministic: no chance involved&lt;/li&gt;
&lt;li&gt;Perfect Information: all aspects of the state are fully observable&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Two-Player Zero-Sum Game&lt;/h2&gt;

&lt;h3&gt;Definition&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;2 players: &lt;code&gt;A&lt;/code&gt;(Max), &lt;code&gt;B&lt;/code&gt;(Min)&lt;/li&gt;
&lt;li&gt;States &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Initial state &lt;code&gt;I&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Terminal positions &lt;code&gt;T&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Successor functions

&lt;ul&gt;
&lt;li&gt;Input: a state&lt;/li&gt;
&lt;li&gt;Return: a set of possible next states&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Utility/Payoff function &lt;code&gt;V: T -&amp;gt; R&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Mapping showing how good each terminal state is for A/how bad for B&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;Intuition&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Game ends when terminal &lt;code&gt;t ∊ T&lt;/code&gt; reached&lt;/li&gt;
&lt;li&gt;Game state: state-player pair&lt;/li&gt;
&lt;li&gt;&lt;code&gt;A&lt;/code&gt; gets &lt;code&gt;V(t)&lt;/code&gt;, &lt;code&gt;B&lt;/code&gt; gets &lt;code&gt;-V(t)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;MiniMax Strategy&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;Build full game tree

&lt;ul&gt;
&lt;li&gt;Root: start state&lt;/li&gt;
&lt;li&gt;Edges: possible moves&lt;/li&gt;
&lt;li&gt;Leaves: terminals (utilities U(t) labeled)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Back balues up the tree

&lt;ul&gt;
&lt;li&gt;`U(n) = min{ U(c): c is a child of n if n is Min node }&lt;/li&gt;
&lt;li&gt;`U(n) = max{ U(c): c is a child of n if n is Max node }&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;O(b^d)&lt;/code&gt; space&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;Depth-First Implementation&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;To avoid expanding the tree exponentially in size&lt;/li&gt;
&lt;li&gt;Need &lt;strong&gt;finite depth&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;DFMiniMax(n, Player): //return Utility of state n given that Player is MIN or MAX

    If n is TERMINAL:
        Return V(n) //Return terminal states utility (V is specified as part of game)

    //Apply Player s moves to get successor states. 
    ChildList = n.Successors(Player)

    If Player == MIN:
        return minimum of DFMiniMax(c, MAX) over c ∈ ChildList
    Else: //Player is MAX
        return maximum of DFMiniMax(c, MIN) over c ∈ ChildList
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;Pruning&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;α-cuts(max node) &amp;amp; β-cuts(min node)&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;AlphaBeta(n,Player,alpha,beta): //return Utility of state 

    If n is TERMINAL:
        return V(n) //Return terminal states utility 

    ChildList = n.Successors(Player)

    If Player == MAX:
        for c in ChildList:
            alpha = max(alpha, AlphaBeta(c,MIN,alpha,beta)) 
            If beta &amp;lt;= alpha:
                break 
    return alpha

    Else: //Player == MIN 
        for c in ChildList:
            beta = min(beta, AlphaBeta(c,MAX,alpha,beta)) 
            If beta &amp;lt;= alpha:
                break 
    return beta

// Initial call: AlphaBeta(START_NODE, PLAYER, -infinity, infinity)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;O(b^d)&lt;/code&gt; space if no pruning, &lt;code&gt;O(b^(d/2))&lt;/code&gt; if optimal pruning

&lt;ul&gt;
&lt;li&gt;Branching factor of 1st layer: B; 2nd: 1; 3rd: B; ...&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;In practice, must make &lt;strong&gt;heuristic estimates&lt;/strong&gt; of the terminal nodes -&amp;gt; &lt;strong&gt;evaluation function&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;Real-Time/Online search&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;Run A* until out of memory&lt;/li&gt;
&lt;li&gt;Use &lt;strong&gt;evaluation function&lt;/strong&gt; to decide which path looks best&lt;/li&gt;
&lt;li&gt;Make the move&lt;/li&gt;
&lt;li&gt;Restart search at the node reached (can be cached)&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Sat, 29 Oct 2016 00:00:00 -0400</pubDate>
        <link>/blog/notes/ai/2016/10/29/game-tree-search.html</link>
        <guid isPermaLink="true">/blog/notes/ai/2016/10/29/game-tree-search.html</guid>
        
        <category>AI</category>
        
        <category>CSC384</category>
        
        <category>search</category>
        
        
        <category>Blog</category>
        
        <category>Notes</category>
        
        <category>AI</category>
        
      </item>
    
      <item>
        <title>Operating System - Unix &amp; Pthread</title>
        <description>&lt;h2&gt;Content&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Process-Related Unix System Calls&lt;/li&gt;
&lt;li&gt;Posix Thread&lt;/li&gt;
&lt;/ol&gt;

&lt;!--more--&gt;

&lt;hr&gt;

&lt;h2&gt;Process-Related Unix System Calls&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;A &lt;code&gt;process&lt;/code&gt; in Unix consistes of an &lt;code&gt;address space&lt;/code&gt; &amp;amp; a &lt;code&gt;thread&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;API

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;getpid()&lt;/code&gt;, &lt;code&gt;getppid()&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Pid identifies &lt;code&gt;address space&lt;/code&gt; &amp;amp; &lt;code&gt;thread&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fork()&lt;/code&gt;, &lt;code&gt;execv()&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Create &lt;code&gt;processes&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;exit()&lt;/code&gt;, &lt;code&gt;wait()&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Terminate &lt;code&gt;processes&lt;/code&gt; &amp;amp; synchronize with terminating &lt;code&gt;process&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kill()&lt;/code&gt;, &lt;code&gt;sigaction()&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Communicate with another &lt;code&gt;process&lt;/code&gt; via &lt;code&gt;signals&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;fork()&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Create &lt;code&gt;childe process&lt;/code&gt; from &lt;code&gt;parent process&lt;/code&gt; with an identical copy of:

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Thread state&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Address space&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;int n = 5;
int pid = fork(); 
if (pid == 0) {
    // run child code
    n = n + 1;
} else { // pid value &amp;gt; 0
    // run parent code
    n = n - 1;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;execv()&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Replaces current &lt;code&gt;process&lt;/code&gt; with a new &lt;code&gt;program&lt;/code&gt;:

&lt;ul&gt;
&lt;li&gt;Loaded from disk&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Code&lt;/code&gt; &amp;amp; &lt;code&gt;data&lt;/code&gt; copied from disk&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Stack&lt;/code&gt; initialized with activation frame of &lt;code&gt;main()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Processor registers&lt;/code&gt; reinitialized&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Pid&lt;/code&gt; stays the same&lt;/li&gt;
&lt;li&gt;Doesn&amp;#39;t return&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;char *cmd = &quot;/bin/ls&quot;; 
char *arg1 = &quot;-l&quot;; 
char *args[3];
args[1] = arg1; 
args[2] = NULL;
execv(cmd, args);
// code doesn’t execute
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;fork()&lt;/code&gt; + &lt;code&gt;execv()&lt;/code&gt; can run a new program as a new process with the old one kept&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;exit(retval)&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Terminate itself:

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Address space&lt;/code&gt; destroyed&lt;/li&gt;
&lt;li&gt;Process-specific OS state destroyed (e.g. open files)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;retval&lt;/code&gt; saved &amp;amp; return to &lt;code&gt;parent process&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;For &lt;code&gt;parent process&lt;/code&gt; to learn about &lt;code&gt;child process&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Thread state&lt;/code&gt; destroyed&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;wait()&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Wait for &lt;code&gt;child process&lt;/code&gt; to terminate; synchronize with &lt;code&gt;child processes&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Returns &lt;code&gt;retval&lt;/code&gt; returned from &lt;code&gt;exit()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;4 cases:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;W&lt;/code&gt; wait starts, &lt;code&gt;C&lt;/code&gt; continue, &lt;code&gt;E&lt;/code&gt; exit starts, &lt;code&gt;D&lt;/code&gt; exit done&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;# Semaphore required for 1, 2, 3

1.
         down(c)  up(p)
Parent ---&amp;gt; W      C-----&amp;gt;
                  / \
Child  --------&amp;gt; E   D
              up(c) down(p)

2.

Parent --------&amp;gt; WC-----&amp;gt;
                 / \
Child  ------&amp;gt; E  | D           # OS keeps child exit retval until wait() is issued by parent,
            (zombie process)    # or destroyed when parent exits

3.

Parent --------&amp;gt; E
                / \
Child  -----&amp;gt; E    D

4.

Parent ---&amp;gt; E

Child  --------&amp;gt; ED
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Each &lt;code&gt;child process&lt;/code&gt; needs a pair of &lt;code&gt;semaphore&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;kill()&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Process send signals to itself or other &lt;code&gt;processes&lt;/code&gt; by calling &lt;code&gt;kill&lt;/code&gt; system call&lt;/li&gt;
&lt;li&gt;Receiver executes &lt;code&gt;signal handler&lt;/code&gt;; if not setup, forced to exit&lt;/li&gt;
&lt;li&gt;Receiver process exits when scheduled to run next

&lt;ul&gt;
&lt;li&gt;Because if receiver is holding the lock, it must be released by itself instead of other threads&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;sigaction()&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Setup &lt;code&gt;signal handler&lt;/code&gt; function&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Posix Thread&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Allows creating additional threads in a &lt;code&gt;Unix process&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;API

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;pthread_create(thread, attr, start_routine, arg)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pthread_exit(status)&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Returns &lt;code&gt;status&lt;/code&gt; to a joining thread&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pthread_join(thread_id, status)&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Block thread until thread with &lt;code&gt;thread_id&lt;/code&gt; terminates&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pthread_yield()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Synchronization API&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Mutex&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;pthread_mutex_t mut = PTHREAD_MUTEX_INITIALIZER;
pthread_mutex_lock(&amp;amp;mut);
pthread_mutex_unlock(&amp;amp;mut)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Monitor&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;int x,y;
pthread_mutex_t mut = PTHREAD_MUTEX_INITIALIZER; 
pthread_cond_t cond = PTHREAD_COND_INITIALIZER;

pthread_mutex_lock(&amp;amp;mut); 
while (x &amp;lt;= y) {
    pthread_cond_wait(&amp;amp;cond, &amp;amp;mut); 
}
/* operate on x and y */ 
pthread_mutex_unlock(&amp;amp;mut);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;pthread_mutex_lock(&amp;amp;mut);
/* modify x and y */
if (x &amp;gt; y) 
    pthread_cond_signal(&amp;amp;cond); 
pthread_mutex_unlock(&amp;amp;mut);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Semaphores&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;sem_t sem name;
sem_init(&amp;amp;sem_name, 0, 0); // (_, flag, init value)
sem_wait(&amp;amp;sem_name);
sem_post(&amp;amp;sem);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Related Articles&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.cs.rutgers.edu/%7Epxk/416/notes/04-processes.html&quot;&gt;Processes - Process Creation and States.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sun, 23 Oct 2016 00:00:00 -0400</pubDate>
        <link>/blog/notes/os/2016/10/23/operating-system-unix-and-pthread.html</link>
        <guid isPermaLink="true">/blog/notes/os/2016/10/23/operating-system-unix-and-pthread.html</guid>
        
        <category>OS</category>
        
        <category>ECE344</category>
        
        <category>unix</category>
        
        <category>pthread</category>
        
        
        <category>Blog</category>
        
        <category>Notes</category>
        
        <category>OS</category>
        
      </item>
    
      <item>
        <title>Operating System - Threads</title>
        <description>&lt;h2&gt;Content&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Threads and Processes&lt;/li&gt;
&lt;li&gt;Thread Scheduling&lt;/li&gt;
&lt;/ol&gt;

&lt;!--more--&gt;

&lt;hr&gt;

&lt;h2&gt;Threads and Processes&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;When a &lt;strong&gt;program&lt;/strong&gt; runs, it is called a &lt;code&gt;process&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;OS maintains states for each abstraction:

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Thread(CPU) state&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;Registers, PC, SP, ...&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Address Space (memory) state&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;Program instructions, static &amp;amp; dynamic data, ...&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Device &amp;amp; other state&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;Open files, network connection state, ...&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;&lt;strong&gt;Threads&lt;/strong&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Abstraction of &lt;strong&gt;virtualizing CPU&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;Each &lt;code&gt;thread&lt;/code&gt; thinks it has its own set of &lt;code&gt;CPU registers&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;# of &lt;code&gt;threads&lt;/code&gt; arbitrary; # of &lt;code&gt;CPUs&lt;/code&gt; fixed&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Enables &lt;strong&gt;concurrency&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Running multiple programs concurrently&lt;/li&gt;
&lt;li&gt;Running multiple tasks concurrently

&lt;ul&gt;
&lt;li&gt;Hiding I/O latency

&lt;ul&gt;
&lt;li&gt;Can use &lt;code&gt;non-blocking file I/O&lt;/code&gt; (&lt;code&gt;event-driven&lt;/code&gt;), but harder to get right because need to build a state machine&lt;/li&gt;
&lt;li&gt;~ &lt;code&gt;interrupts&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Run truly in parallel with multiple &lt;code&gt;CPUs&lt;/code&gt; via &lt;code&gt;multiplexing&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Threads v.s. Functions&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align: left&quot;&gt;Threads&lt;/th&gt;
&lt;th style=&quot;text-align: left&quot;&gt;Functions&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Independent streams of execution, one thread no need to run to the end before switching&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;LIFO policy, functions runs untill the end&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Thread scheduler multiplexes the threads on CPU&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;One function calls another function&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Each thread has its own stack, calling its own set of functions&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Running on a single stack&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Runs in parallel with multiprocessors&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Cannot run in parallel with multiprocessors because functions stack together&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;&lt;strong&gt;Address Space&lt;/strong&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Abstraction of &lt;strong&gt;virtualizing memory&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;A set of &lt;em&gt;virtual memory regions&lt;/em&gt; accessible to a program

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Text&lt;/code&gt;: program code&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Data&lt;/code&gt;, &lt;code&gt;Heap&lt;/code&gt;: static, dynamic variables&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Stack&lt;/code&gt;: for function &amp;amp; system calls&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Provides &lt;strong&gt;memory protection&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Address space (order may vary with different H/W &amp;amp; compiler environment)&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;        +++++++++++++++ ----
        |    param    |  |
        +++++++++++++++  |
        |   ret val   |  |
        +++++++++++++++  |
        |   ret addr  |  |  activation frame
        +++++++++++++++  |  for current function
  fp -&amp;gt; |   prev fp   |  |
        +++++++++++++++  |
        |  other regs |  |
        +++++++++++++++  |
  sp -&amp;gt; |  local var  |  |      # function call:
        +++++++++++++++ ----    # push %rbp; save old fp
        |      ↓      |         # mov %rbp %rsp; init sp to fp
        |             |         # retq; call *sp
        |      ↑      |
        +++++++++++++++         # return:
        |    data     |         # add $24 %rsp; pop off stack
        +++++++++++++++         # pop %rbp; fp=*sp (or *fp), sp++
        |    text     |         # retq; call *sp
        +++++++++++++++
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;&lt;strong&gt;Processes&lt;/strong&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;A running program consistes of &amp;gt;= 1 processes

&lt;ul&gt;
&lt;li&gt;Traditionally:

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;process = addr space + thread&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Threads&lt;/code&gt; communicate using &lt;code&gt;system calls&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Today:

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;process = addr space + &amp;gt;= 1 threads&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Threads&lt;/code&gt; share &lt;code&gt;addr space&lt;/code&gt; (but not &lt;code&gt;stack&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Threads&lt;/code&gt; communicate with &lt;code&gt;reading/writing memory&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Speed up cases analysis:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;# Vector operation
for (k = 0; k &amp;lt; n; k++)
    a[k] = b[k]*c[k] + d[k]*e[k];
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Multiple processes?

&lt;ul&gt;
&lt;li&gt;Communicate with &lt;code&gt;system call&lt;/code&gt;...&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Multiple threads?

&lt;ul&gt;
&lt;li&gt;Must make it global to share data&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;On single processor?

&lt;ul&gt;
&lt;li&gt;Threads go one after another&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;On multiprocessor?

&lt;ul&gt;
&lt;li&gt;O&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;# Web server
Loop:
    1. get network message from client -&amp;gt; I/O
    2. get URL data form disk, cache in memory -&amp;gt; I/O
    3. compose response
    4. send response -&amp;gt; I/O
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Multiple processes?

&lt;ul&gt;
&lt;li&gt;Cannot share the cache (stored in global resource area of that process)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Multiple threads?

&lt;ul&gt;
&lt;li&gt;O&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;On single processor?

&lt;ul&gt;
&lt;li&gt;O&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;On multiprocessor?

&lt;ul&gt;
&lt;li&gt;O&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Threads v.s. Processes&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align: left&quot;&gt;&lt;/th&gt;
&lt;th style=&quot;text-align: left&quot;&gt;Threads&lt;/th&gt;
&lt;th style=&quot;text-align: left&quot;&gt;Processes&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Memory needed&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Shared, less&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Not shared, more&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Communication &amp;amp; Synchronization&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Via &lt;strong&gt;shared vars&lt;/strong&gt;, faster&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Via &lt;strong&gt;system calls&lt;/strong&gt;, slower&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Switching&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Save &amp;amp; restore regs, faster&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Change MMU&amp;#39;s regs (e.g. base &amp;amp; limit), slower&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Robustness&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Memory sharing -&amp;gt; bugs&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Communication explicit -&amp;gt; robust&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Program v.s. Process&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Program&lt;/strong&gt;: a set of instructions &amp;amp; data&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Process&lt;/strong&gt;: a program loaded in memory and executing&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;&lt;strong&gt;OS-Level Process State&lt;/strong&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;OS keeps state for each process: &lt;code&gt;process state&lt;/code&gt;, &lt;code&gt;process control block (PCB)&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Thread state&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Processor regs&lt;/code&gt; for resuming/suspending thread&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Thread id&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Various &lt;code&gt;parameters&lt;/code&gt; e.g. scheduling parameters&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Address space state&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;Location of &lt;code&gt;text&lt;/code&gt;, &lt;code&gt;data&lt;/code&gt;, &lt;code&gt;stack&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;MMU virtual memory state&lt;/code&gt; i.e. virtual -&amp;gt; physical mapping&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Device related state&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;Open files, network connections&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Other states&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;Terminal state, pending signals, timers, swap, ...&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr&gt;

&lt;h2&gt;Thread Scheduling&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Thread&lt;/code&gt;: an independent stream of instructions

&lt;ul&gt;
&lt;li&gt;Which to choose?&lt;/li&gt;
&lt;li&gt;When to switch?&lt;/li&gt;
&lt;li&gt;How to switch?&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Thread scheduling&lt;/code&gt;: running threads in some order

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Thread state&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Running&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Ready&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Blocked&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Exited&lt;/code&gt; (not yet destroyed)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Scheduling policies&lt;/code&gt; to change states&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Thread scheduling functions&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;thread_yield&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Running -&amp;gt; Ready&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;thread_sleep&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Running -&amp;gt; Blocked&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;thread_wakeup&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Blocked -&amp;gt; Ready&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Preemptive scheduling&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Scheduler&lt;/code&gt; uses &lt;code&gt;timer interrupt&lt;/code&gt; to control threads&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Interrupt handler&lt;/code&gt; calls yield on behalf of running thread

&lt;ul&gt;
&lt;li&gt;Normally &lt;code&gt;interrupt handler&lt;/code&gt; returns to original call; here, it calls &lt;code&gt;thread_yield()&lt;/code&gt; instead&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Scheduler implementation

&lt;ul&gt;
&lt;li&gt;Thread structures maintained in &lt;code&gt;queues&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Ready queue&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Generally 1 per CPU&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Wait queue&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Separate &lt;code&gt;wait queues&lt;/code&gt; for each type of event e.g. disk, console, timer, network, ...&lt;/li&gt;
&lt;li&gt;Generally shared by CPUs&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Exited queue&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Generally shared by CPUs&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Scheduling functions&lt;/code&gt; move &lt;code&gt;threads&lt;/code&gt; between &lt;code&gt;queues&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;&lt;strong&gt;Thread &amp;amp; Context Switch&lt;/strong&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;context switch&lt;/code&gt; (&lt;code&gt;process switch&lt;/code&gt;) = &lt;code&gt;thread switch&lt;/code&gt; + &lt;code&gt;address space switch&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Address space switch&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Updating &lt;code&gt;MMU&amp;#39;s&lt;/code&gt; registers&lt;/li&gt;
&lt;li&gt;More expensive than &lt;code&gt;thread switch&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Context switch&lt;/code&gt; v.s. &lt;code&gt;Mode switch&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Unrelated; the former switch threads, the latter switch CPU modes&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Functions&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;thread_yield&lt;/code&gt;&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;thread_yield() {
    enqueue_ready_queue(current)
    next = choose_next_thread()
    thread_switch(current, next)
}
thread_switch(current, next) {
    save_processor_state(current-&amp;gt;cpu_regs)
    ...
    restore_processor_state(next-&amp;gt;cpu_regs)
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;thread_init&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Create the first (main) thread&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;thread_create&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Allocate thread struct, stack memory, init PC, SP&lt;/li&gt;
&lt;li&gt;Add to ready queue&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;&lt;strong&gt;Thread Creation &amp;amp; Termination&lt;/strong&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Functions

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;thread_exit&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Does not destroy itself; switch to another thread and it will destroy this thread&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;thread_destroy&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Actually destroy thread structure &amp;amp; stack of exited threads&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;&lt;strong&gt;Kernel Threads v.s. User Threads&lt;/strong&gt;&lt;/h3&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align: left&quot;&gt;&lt;/th&gt;
&lt;th style=&quot;text-align: left&quot;&gt;Kernel Threads&lt;/th&gt;
&lt;th style=&quot;text-align: left&quot;&gt;User Threads&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Implementation scope&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Implemented in kernel&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Implemented in user program&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Virtualization&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Virtualize CPU&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Virtualize kernel thread&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Switching cost&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Must run kernel code, expensive&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;~procedure calls, less expensive&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Scheduling policy&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Fixed&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Custom definition&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Blocking system calls&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Switch to another kernel thread&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;All threads (associated with the same kernel thread) block -&amp;gt; overlap of I/O &amp;amp; computations impossible&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Multiprocessors&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Threads use multiple CPUs concurrently&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Cannot use multiple CPUs consurrently&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Kernel level scheduler&lt;/code&gt; doesn&amp;#39;t know about &lt;code&gt;user threads&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr&gt;

&lt;h2&gt;&lt;strong&gt;Quick Questions&lt;/strong&gt;&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Is the OS code run in a separate process? A separate thread? Does it need a process structure?

&lt;ul&gt;
&lt;li&gt;OS code runs when a process makes a system call or when an interrupt occurs. In either case, the OS generally runs in the thread and address space context of the user process, and hence it does not require its own process or thread state.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;What is the address space of an OS?

&lt;ul&gt;
&lt;li&gt;The entire physical memory&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2&gt;Related Articles&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://www.quora.com/How-does-thread-switching-differ-from-process-switching&quot;&gt;Thread Switching v.s. Process Switching&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sun, 23 Oct 2016 00:00:00 -0400</pubDate>
        <link>/blog/notes/os/2016/10/23/operating-system-threads.html</link>
        <guid isPermaLink="true">/blog/notes/os/2016/10/23/operating-system-threads.html</guid>
        
        <category>OS</category>
        
        <category>ECE344</category>
        
        <category>threads</category>
        
        
        <category>Blog</category>
        
        <category>Notes</category>
        
        <category>OS</category>
        
      </item>
    
      <item>
        <title>Operating System - Scheduling</title>
        <description>&lt;h2&gt;Content&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Scheduling Overview&lt;/li&gt;
&lt;li&gt;Scheduling Policies&lt;/li&gt;
&lt;li&gt;Multiprocessor Scheduling&lt;/li&gt;
&lt;/ol&gt;

&lt;!--more--&gt;

&lt;hr&gt;

&lt;h2&gt;Scheduling Overview&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Prevent &lt;code&gt;thread starvation&lt;/code&gt;, BUT &lt;code&gt;context switching&lt;/code&gt; is expensive&lt;/li&gt;
&lt;li&gt;Runs another program when I/O performed&lt;/li&gt;
&lt;li&gt;Goals

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Batch systems&lt;/strong&gt;: Long running, no interactive users, no time constraints

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;CPU utilization&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;% of time CPU is busy&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Throughput&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;# of programs complete per unit time&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Turnaround time&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Total time to finish a program&lt;/li&gt;
&lt;li&gt;&lt;code&gt;turnaround = processing + waiting&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Interactive (general-purpose) systems&lt;/strong&gt;: Short running, interactive suers, weak time constraints

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Response time&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Time between &lt;em&gt;receiving request&lt;/em&gt; &amp;amp; starting to &lt;em&gt;produce output&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Scheduling Policies&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Batch systems&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;Policies

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;FIFO&lt;/code&gt; (non-preemptive)

&lt;ul&gt;
&lt;li&gt;In order of arrival time&lt;/li&gt;
&lt;li&gt;Run thread until completion&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Shortest job first&lt;/code&gt; (non-preemptive)

&lt;ul&gt;
&lt;li&gt;In order of shortest running time&lt;/li&gt;
&lt;li&gt;Run thread until completion&lt;/li&gt;
&lt;li&gt;Starving long jobs&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Shortest remaining time&lt;/code&gt; (preemptive)

&lt;ul&gt;
&lt;li&gt;In order of shortest remaining time&lt;/li&gt;
&lt;li&gt;Run thread until completion OR another thread arrives&lt;/li&gt;
&lt;li&gt;Preemptive version of &lt;code&gt;shortest job first&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Starving long jobs&lt;/li&gt;
&lt;li&gt;Optimal w.r.t. avg waiting time&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Properties

&lt;ul&gt;
&lt;li&gt;Some require estimate of preocessing time&lt;/li&gt;
&lt;li&gt;May starve long running threads&lt;/li&gt;
&lt;li&gt;Long response time&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Interactive systems&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;Policies

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Round-Robin&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Preemptive version of &lt;code&gt;FIFO&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Time slice&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Upper time bound each process runs &lt;/li&gt;
&lt;li&gt;&lt;code&gt;time slice &amp;gt;&amp;gt; context switch time&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cs overhead = cs/(ts+cs)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Run thread until &lt;code&gt;time slice&lt;/code&gt; interrupt OR thread blocks&lt;/li&gt;
&lt;li&gt;Effectiveness:

&lt;ul&gt;
&lt;li&gt;# of threads&lt;/li&gt;
&lt;li&gt;Size of &lt;code&gt;time slice&lt;/code&gt;&lt;br&gt;
&lt;strong&gt;Long&lt;/strong&gt; -&amp;gt; slow response&lt;br&gt;
&lt;strong&gt;Short&lt;/strong&gt; -&amp;gt; high overhead&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Does not require estimation of job processing time; no &lt;code&gt;starvation&lt;/code&gt;; enables &lt;code&gt;interactivity&lt;/code&gt; by limiting the amount of time each thread can run&lt;/li&gt;
&lt;li&gt;Reduces &lt;code&gt;throughtput&lt;/code&gt; due to frequent &lt;code&gt;context switching&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Static priority&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;In order of priority assigned&lt;/li&gt;
&lt;li&gt;Starving low prioriy threads&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Priority inversion&lt;/em&gt;: low priority threads holding locks that high priority threads want&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Multi-level queue&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;High, medium, &amp;amp; low PQs&lt;/li&gt;
&lt;li&gt;Choose from high-priority PQ first (e.g. I/O threads)&lt;/li&gt;
&lt;li&gt;For each queue, &lt;code&gt;round-robin&lt;/code&gt; scheduling&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Dynamic priority (feedback)&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Priority changed based on thread behavior; CPU-bound threads have priority reduced&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Feedback scheduling&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Goals

&lt;ul&gt;
&lt;li&gt;Allocate CPU fairly&lt;/li&gt;
&lt;li&gt;I/O-bound threads receive higher priority&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Each thread:

&lt;ul&gt;
&lt;li&gt;CPU usage (C)&lt;/li&gt;
&lt;li&gt;Current priority (Pi)&lt;/li&gt;
&lt;li&gt;Initial priority (P0)&lt;/li&gt;
&lt;li&gt;Nice value (N)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Steps

&lt;ol&gt;
&lt;li&gt;Scheduler chooses thread with the &lt;strong&gt;smallest&lt;/strong&gt; Pi&lt;/li&gt;
&lt;li&gt;On timer interrupt, update CPU C of running thread &lt;code&gt;C = C + 1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Every time slice, update Pi &lt;code&gt;Pi = Pi-1/2 + C + N&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Reset C for all threads&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Time slice&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Many interrupts in between &lt;code&gt;time slice&lt;/code&gt; to avoid excessive &lt;code&gt;context switches&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;A &lt;code&gt;thread&lt;/code&gt; runs for a full &lt;code&gt;time slice&lt;/code&gt; unless:

&lt;ul&gt;
&lt;li&gt;The &lt;code&gt;thread&lt;/code&gt; blocks&lt;/li&gt;
&lt;li&gt;Some blocked &lt;code&gt;thread&lt;/code&gt; wakesup&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Longer &lt;code&gt;time slice&lt;/code&gt; improves throughput&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Multiprocessor Scheduling&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Asymetric multiprocessing

&lt;ul&gt;
&lt;li&gt;1 processor runs all OS code, I/O processing code, etc.&lt;/li&gt;
&lt;li&gt;Others run user code&lt;/li&gt;
&lt;li&gt;Simple implementation&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Symmetric multiprocessing (SMP)

&lt;ul&gt;
&lt;li&gt;All processors fun OS &amp;amp; user code&lt;/li&gt;
&lt;li&gt;Efficient&lt;/li&gt;
&lt;li&gt;Difficult implementation&lt;/li&gt;
&lt;li&gt;Scheduling issues

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Processor affinity&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;Cache issue, want to ensure &lt;code&gt;threads&lt;/code&gt; run on the same &lt;code&gt;thread&lt;/code&gt; before&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Hard affinity&lt;/code&gt;: a &lt;code&gt;thread&lt;/code&gt; specifies which processor it wants to use&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Load balancing&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;Single ready queue: easy BUT tends to bottleneck because each processor needs a spinlock for ready queue&lt;/li&gt;
&lt;li&gt;1 ready queue per processor: scalable BUT &lt;em&gt;task migration&lt;/em&gt; &amp;amp; &lt;em&gt;load balancing&lt;/em&gt; tricky&lt;br&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;task migration&lt;/em&gt;  -&lt;br&gt;
Deadlock?&lt;/li&gt;
&lt;li&gt;&lt;em&gt;load balancing&lt;/em&gt;  -&lt;br&gt;
&lt;code&gt;Push migration&lt;/code&gt;: thread find less-busy processors&lt;br&gt;
&lt;code&gt;Pull migration&lt;/code&gt;: idle processor find thread on busy processors&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sun, 23 Oct 2016 00:00:00 -0400</pubDate>
        <link>/blog/notes/os/2016/10/23/operating-system-scheduling.html</link>
        <guid isPermaLink="true">/blog/notes/os/2016/10/23/operating-system-scheduling.html</guid>
        
        <category>OS</category>
        
        <category>ECE344</category>
        
        <category>scheduling</category>
        
        
        <category>Blog</category>
        
        <category>Notes</category>
        
        <category>OS</category>
        
      </item>
    
      <item>
        <title>Operating System - Memory Management</title>
        <description>&lt;h2&gt;Content&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Introduction to Memory Management&lt;/li&gt;
&lt;li&gt;Managing Memory with Bitmaps &amp;amp; Lists&lt;/li&gt;
&lt;li&gt;Simple Memory Management &amp;amp; Fragmentation&lt;/li&gt;
&lt;/ol&gt;

&lt;!--more--&gt;

&lt;hr&gt;

&lt;h2&gt;Introduction to Memory Management&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Requirements

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Isolation&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Abstraction&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sharing&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Goals

&lt;ul&gt;
&lt;li&gt;Low memory overhead&lt;/li&gt;
&lt;li&gt;Low performance overhead&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Supports

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Compiler&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;Source file to object file&lt;/li&gt;
&lt;li&gt;Generates &lt;em&gt;relocatable&lt;/em&gt; &lt;code&gt;virtual memeory addresses&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Linker&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;Links multiple object files to single program on disk&lt;/li&gt;
&lt;li&gt;Generates &lt;em&gt;absolute&lt;/em&gt; &lt;code&gt;virtual memeory addresses&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OS&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;Loads program into &lt;code&gt;physical memory&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Sets up &lt;code&gt;virtual memory H/W&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;H/W&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;Translates &lt;code&gt;virtual memory&lt;/code&gt; to &lt;code&gt;physical memory&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;S/W too slow for address translation&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Managing Memory with Bitmaps &amp;amp; Lists&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;After &lt;code&gt;boot loader&lt;/code&gt; loads OS code &amp;amp; dage in low memory, &lt;code&gt;OS&lt;/code&gt; keeps track of &lt;code&gt;allocated&lt;/code&gt; &amp;amp; &lt;code&gt;free&lt;/code&gt; memory&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Bitmap&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1 bit per chunk of memory; in use or not&lt;/li&gt;
&lt;li&gt;Larger chunk size, lower overhead BUT more &lt;strong&gt;internal fragmentation&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;|--OS code data--| bit map | chunk1 | chunk2 | ... |
                  01101...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Linked Lists&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A list of elements for each allocated or free region of memory&lt;/li&gt;
&lt;li&gt;Allocated bit + starting address + length + pointer&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;| A |   f   |  B  | C | f |    D    | E | f | ... |

| a | 0 | 5 | [] | --&amp;gt; | f | 5 | 3 | [] | --&amp;gt; ...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Searching

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;First fit&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Best fit&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Quick fit&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Under which conditions is each approach preferable?&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Simple Memory Management &amp;amp; Fragmentation&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Internal fragmentation&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;Program doesn&amp;#39;t use entire region -&amp;gt; paddings&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;External fragmentation&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;A large region cannot be allocated even enough memory exists

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Compaction&lt;/em&gt;: move processes around, but expensive&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sun, 23 Oct 2016 00:00:00 -0400</pubDate>
        <link>/blog/notes/os/2016/10/23/operating-system-memory-management.html</link>
        <guid isPermaLink="true">/blog/notes/os/2016/10/23/operating-system-memory-management.html</guid>
        
        <category>OS</category>
        
        <category>ECE344</category>
        
        <category>memory management</category>
        
        
        <category>Blog</category>
        
        <category>Notes</category>
        
        <category>OS</category>
        
      </item>
    
      <item>
        <title>Operating System - Concurrent Programming</title>
        <description>&lt;h2&gt;Content&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Concurrent Programming&lt;/li&gt;
&lt;li&gt;Mutual Exclusion&lt;/li&gt;
&lt;li&gt;Synchronization&lt;/li&gt;
&lt;/ol&gt;

&lt;!--more--&gt;

&lt;hr&gt;

&lt;h2&gt;Concurrent Programming&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Threads&lt;/code&gt; cooperate to perform a common task by sharing data (global vars &amp;amp; heap data)&lt;/li&gt;
&lt;li&gt;Problems

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Race conditions&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Thread interleaving&lt;/code&gt; cause incorrect results&lt;/li&gt;
&lt;li&gt;Access to shared variable must be exclusive&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Synchronization&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;Ordering between threads must be enforced&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Mutual Exclusion&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Atomic operation&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Operation appears &lt;em&gt;indivisible&lt;/em&gt;; rest of the system either doesn&amp;#39;t observe any of the effects, or all of them&lt;/li&gt;
&lt;li&gt;Other threads may still run, but they should not observe any intermediate states of the operation&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Mutual exclusion&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Only one thread can read/update shared variables at a time&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Critical section&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;The code region where &lt;code&gt;mutual exclusion&lt;/code&gt; is enforced&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;&lt;strong&gt;Mutex Lock&lt;/strong&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Critical sections&lt;/code&gt; accessed in between &lt;code&gt;lock&lt;/code&gt;, &lt;code&gt;unlock&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Functions

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;mutex = lock_create()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lock_destroy(mutex)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lock(mutex)&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;If lock free: acquire lock&lt;/li&gt;
&lt;li&gt;Else: wait/sleep until lock free&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;unlock(mutex)&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Release lock&lt;/li&gt;
&lt;li&gt;Wake up one of the waiting threads&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Mutual exclusion&lt;/code&gt; conditions

&lt;ul&gt;
&lt;li&gt;NO 2 threads in &lt;code&gt;critical section&lt;/code&gt; at the same time&lt;/li&gt;
&lt;li&gt;NO assumption on speed of thread execution&lt;/li&gt;
&lt;li&gt;Thread running outside &lt;code&gt;critical section&lt;/code&gt; CANNOT block another thread&lt;/li&gt;
&lt;li&gt;NO thread must wait forever to enter its &lt;code&gt;critical section&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;&lt;strong&gt;Mutex Implementation&lt;/strong&gt;&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Variable tracking&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;lock(l) {
    while (l == TRUE)
        ;
    l = TRUE;
}
unlock(l) {
    l = FALSE;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;l&lt;/code&gt; is also a shared variable, so &lt;code&gt;lock&lt;/code&gt; &amp;amp; &lt;code&gt;unlock&lt;/code&gt; should be &lt;code&gt;atomic&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Make &lt;code&gt;lock&lt;/code&gt; atomic&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;lock(l) {
    disable_interupts;
    while (l == TRUE)
        ;
    l = TRUE;
}
unlock(l) {
    l = FALSE;
    enable_interupts;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Works only on &lt;em&gt;single core&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;h4&gt;Multiprocessor H/W provides &lt;code&gt;atomic instructions&lt;/code&gt;&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Test-and-set&lt;/code&gt; lock, &lt;code&gt;compare-and-swap&lt;/code&gt; lock&lt;/li&gt;
&lt;li&gt;Operate on a memory word, perform 2 operations &lt;strong&gt;indivisibly&lt;/strong&gt; by CPU requesting the lock controller to lock out the memory location&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;      int tset(int *lock) { // atomic in H/W
          int old = *lock;
          *lock = 1;  ___&amp;gt; atomic
          return old; _|
      }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;Spin locks&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Uses &lt;code&gt;tset&lt;/code&gt; in a loop&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;// *l init to 0
lock(int *l) {
    while (tset(1))
        ;
}
unlock(int *l) {
    *l = FALSE;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Efficient only if &lt;code&gt;critical sections&lt;/code&gt; are short&lt;/li&gt;
&lt;li&gt;But &lt;code&gt;CPU&lt;/code&gt; performs no useful working waiting in the loop -&amp;gt; &lt;strong&gt;waste CPU&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;Yielding locks&lt;/code&gt;&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;// *l init to 0
lock(int *l) {
    while (tset(1))
        thread_yield();
}
unlock(int *l) {
    *l = FALSE;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;But scheduler determines when it returns back -&amp;gt; &lt;strong&gt;delay lock acquire&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;Blocking locks&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Unlike 3., 4. polling for locks, now &lt;code&gt;unlock&lt;/code&gt; will wakeup threads sleeping in &lt;code&gt;lock&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;// *l init to 0
lock(int *l) {
    while (tset(1))
        thread_sleep();
}
unlock(int *l) {
    *l = FALSE;
    thread_wakeup();
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Access shared &lt;code&gt;ready queue&lt;/code&gt;, i.e. we need locking while implementing blocking&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Locking solutions&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Multiprocessor&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;                blocking lock    # manipulate queues
                      ↓
                  spin lock      # loop on atomic instruction
                      ↓
              atomic instruction # single instruction
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Uniprocessor&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;                blocking lock
                      ↓
              interrupt disabling
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Which lock to use?&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align: left&quot;&gt;Lock&lt;/th&gt;
&lt;th style=&quot;text-align: left&quot;&gt;When to use?&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Atomic instruction&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Most efficient, use when available&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Interrupt disabling, spin locks&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Critical sections short &amp;amp; will not block&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Blocking locks&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Critical sections long &amp;amp; may block (&lt;strong&gt;for synchronization&lt;/strong&gt;); overhead for context switch&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;How many locks to create?&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1 per individual data structure&lt;/li&gt;
&lt;li&gt;More locks -&amp;gt; more parallelism BUT more bugs&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Why do we need &lt;code&gt;spin lock&lt;/code&gt; when implementing &lt;code&gt;blocking lock&lt;/code&gt;?&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Avoid &lt;code&gt;lost wakeup&lt;/code&gt; between checking availability of lock &amp;amp; sleep&lt;/li&gt;
&lt;li&gt;Need another locking method to protect the shared ready queue&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;&lt;strong&gt;Deadlocks, Starvation, Livelock&lt;/strong&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Deadlock&lt;/code&gt;: a set of threads each waiting for a resource held by another thread

&lt;ul&gt;
&lt;li&gt;Conditions

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Mutual exclusion&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hold &amp;amp; wait&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;No premption&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Circular wait&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Prevention

&lt;ul&gt;
&lt;li&gt;Release previously acquired locks? (hold &amp;amp; wait)

&lt;ul&gt;
&lt;li&gt;But modifications to data might have already happened&lt;/li&gt;
&lt;li&gt;Or &lt;code&gt;livelock&lt;/code&gt; when keep trying to acquire locks&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Number each resources, need to acquire lower numbered resources before higher ones? (circular wait)

&lt;ul&gt;
&lt;li&gt;Difficult to number a whole bunch, and some of them are from third-party&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Starvation&lt;/code&gt;: a set of threads waiting for resources constantly used by others&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Livelock&lt;/code&gt;: a set of threads continue to num but make no progress

&lt;ul&gt;
&lt;li&gt;e.g. &lt;code&gt;interrupt livelock&lt;/code&gt;: interrupts queueing up and suspend the running threads
=&amp;gt; Can turn to &lt;code&gt;polling&lt;/code&gt;, with intervals not too long&lt;/li&gt;
&lt;li&gt;Need to ensure a thread runs for a while before switching&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr&gt;

&lt;h2&gt;Synchronization&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Threads&lt;/code&gt; wait on some conditions before proceeding&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;&lt;strong&gt;Motivation: Producer-Consumer Problem&lt;/strong&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Single producer &amp;amp; consumer&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;char buf[8];
int in;
int out;

void send(char msg) {
    while ((in-out+n) % n == n-1)
        ; // full
    buf[in] = msg;
    in = (in+1) % n;
}

char receive() {
    while (in == out)
        ; // empty
    msg = buf[out];
    out = (out+1) % n;
    return msg;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Multiple producers &amp;amp; consumers&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;# deadlock

void send(char msg) {
    lock(l);
    while ((in-out+n) % n == n-1)
        ; // full
    buf[in] = msg;
    in = (in+1) % n;
    unlock(l);
}

char receive() {
    lock(l);
    while (in == out)
        ; // empty
    msg = buf[out];
    out = (out+1) % n;
    return msg;
    unlock(l);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;# release locks before spinning - too tight

void send(char msg) {
    lock(l);
    while ((in-out+n) % n == n-1) {
        unlock(l);
        lock(l);
    }
    buf[in] = msg;
    in = (in+1) % n;
    unlock(l);
}

char receive() {
    lock(l);
    while (in == out) {
        unlock(l);
        lock(l);
    }
    msg = buf[out];
    out = (out+1) % n;
    return msg;
    unlock(l);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;# sleep after unlocking

void send(char msg) {
    lock(l);
    while ((in-out+n) % n == n-1) {
        unlock(l);          ____&amp;gt; atomic! Or else lost wakeup
        thread_sleep(full); __|
        lock(l);
    }
    buf[in] = msg;
    if (in == out)
        thread_wakeup(empty);
    in = (in+1) % n;
    unlock(l);
}

char receive() {
    lock(l);
    while (in == out) {
        unlock(l);
        thread_sleep(empty);
        lock(l);
    }
    msg = buf[out];
    if ((in-out+n) % n == n-1)
        thread_wakeup(full);
    out = (out+1) % n;
    unlock(l);
    return msg;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Challenges&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Can&amp;#39;t spin or sleep while holding lock

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Deadlock&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Can&amp;#39;t release lock and then sleep

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Lost wakeup&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Need to &lt;strong&gt;unlock &amp;amp; sleep atomically&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;&lt;strong&gt;Monitors&lt;/strong&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Condition variable&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Used within &lt;code&gt;monitor methods&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Functions

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cv = cv_create()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cv_destroy(cv)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cv_wait(cv, lock)&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Lock released &lt;code&gt;atomically&lt;/code&gt; while waiting&lt;/li&gt;
&lt;li&gt;Lock reacquired after wait returns&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cv_signal(cv, lock)&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Wakeup one thread waiting on the condition&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Lost signal&lt;/code&gt;: signal occurs before a wait&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cv_broadcast(cv, lock)&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Wakeup all threads waiting on the condition&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Basis&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;F() {
    int disabled = disaple_interrupt;
    do_work();
    enable_interrupt(disabled);
}
do_work(){
    int disabled = disaple_interrupt; // already disabled!
    ...
    enable_interrupt(disabled); // stay disabled
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;Producer-consumer&lt;/code&gt; with &lt;code&gt;monitors&lt;/code&gt;&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;buf[n], in, out;
lock l = 0;
cv full;
cv empty;

void send(char msg) {
    lock(l);
    while ((in-out+n) % n == n-1) {
        // put thread into wait queue for 'full' condition
        wait(full, l); // unlock + sleep + lock
    }
    buf[in] = msg;
    if (in == out)
        signal(empty, l);
    in = (in+1) % n;
    unlock(l);
}

char receive() {
    lock(l);
    while (in == out) {
        wait(empty, l);
    }
    msg = buf[out];
    if ((in-out+n) % n == n-1)
        signal(full, l);
    out = (out+1) % n;
    unlock(l);
    return msg;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;Variable initialization&lt;/code&gt; with &lt;code&gt;monitors&lt;/code&gt;&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;Method1() {
    lock(l);
    V = malloc(...);
    signal(cv, l); // condition = V is null
    ...
    unlock(l);
}
Method2() {
    lock(l);
    if (V == NULL)
        wait(cv, l); // condition = V is null
    assert(V);
    unlock(l);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Lock&lt;/code&gt; is for avoiding &lt;code&gt;lost wakeup&lt;/code&gt; because &lt;code&gt;signal&lt;/code&gt; CANNOT come before &lt;code&gt;wait&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;&lt;strong&gt;Semaphores&lt;/strong&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Tracks number of available resources using &lt;code&gt;down&lt;/code&gt; &amp;amp; &lt;code&gt;up&lt;/code&gt;&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;# spinning (example with race condition on s)

down() {
    while (s &amp;lt;= 0)
        ;
    s--;
}
up() {
    s++;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;# blocked

down() {
    disable_interrupts;
    while (s &amp;lt;= 0)
        thread_sleep(s);
    s--;
    enable_interrupts;
}
up() {
    disable_interrupts;
    s++;
    thread_wakeup(s);
    enable_interrupts;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;If &lt;code&gt;s&lt;/code&gt; init to &lt;code&gt;1&lt;/code&gt;, then behaves like &lt;code&gt;lock&lt;/code&gt; &amp;amp; &lt;code&gt;unlock&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Difference with &lt;code&gt;lock&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Different&lt;/strong&gt; threads call &lt;code&gt;down&lt;/code&gt; &amp;amp; &lt;code&gt;up&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;up&lt;/code&gt; can happen &lt;strong&gt;before&lt;/strong&gt; &lt;code&gt;down&lt;/code&gt; to bank resource&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;Producer-consumer&lt;/code&gt; with &lt;code&gt;semaphores&lt;/code&gt;&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;buf[n], in, out;
lock l;
sem full = 0;
sem empty = n;

void send(char msg) {
    down(empty);
    lock(l);
    buf[in] = msg;
    in = (in+1) % n;
    unlock(l);
    up(full);
}

char receive() {
    down(full);
    lock(l); // this lock for buf, not for avoiding lost signal
    msg = buf[out];
    out = (out+1) % n;
    unlock(l);
    up(empty);
    return msg;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr&gt;

&lt;h2&gt;&lt;strong&gt;Quick Questions&lt;/strong&gt;&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;What is the difference between mutual exclusion and synchronization?

&lt;ul&gt;
&lt;li&gt;Mutex: used to ensure that only one thread accesses a critical section at a time, ensuring that operations are run atomically.&lt;/li&gt;
&lt;li&gt;Synchronization: used to ensure threads wait on some condition.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Why are locks, by themselves, not sufficient for solving synchronization problems?

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Lock&lt;/code&gt; &amp;amp; &lt;code&gt;unlock&lt;/code&gt; are used together and in that order. Synchronization problems require a more general primitive: conditional &lt;code&gt;sleep&lt;/code&gt; and &lt;code&gt;wakeup&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;What are the differences between a monitor and a semaphore?

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Monitor&lt;/code&gt; requires locks to avoid lost signal. &lt;/li&gt;
&lt;li&gt;&lt;code&gt;Monitor&lt;/code&gt; is associated with a lock; &lt;code&gt;semaphore&lt;/code&gt; only use locks to protect the shared resource.&lt;/li&gt;
&lt;li&gt;No lost wakeups for &lt;code&gt;semaphore&lt;/code&gt; because the wakeups (&lt;code&gt;up()&lt;/code&gt;) will not be dedicated to a specific thread but instead used for future entries.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Down/Up&lt;/code&gt; &amp;amp; &lt;code&gt;wait/signal&lt;/code&gt; are also different.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;What are the differences between &lt;code&gt;wait()&lt;/code&gt; and &lt;code&gt;down()&lt;/code&gt;?

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Wait&lt;/code&gt; is stateless, it always waits. &lt;code&gt;Wait&lt;/code&gt; also releases a lock, waits, and then reacquires a lock. &lt;/li&gt;
&lt;li&gt;&lt;code&gt;Down&lt;/code&gt; has state embedded with a notion of available resources, and will only wait if resources are not available. &lt;code&gt;Down&lt;/code&gt; doesn’t have any notion of an associated lock.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;What are the differences between &lt;code&gt;signal()&lt;/code&gt; and &lt;code&gt;up()&lt;/code&gt;?

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Signal&lt;/code&gt; can be lost if no one is waiting, hence the need to use locks with condition variables, so that there is no race with &lt;code&gt;wait&lt;/code&gt;. &lt;/li&gt;
&lt;li&gt;&lt;code&gt;Up&lt;/code&gt; will always increase the resource available, so a future down can acquire the resource. &lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Why might you prefer one over the other?

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Semaphore&lt;/code&gt;: resource counting problem&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Monitor&lt;/code&gt;: other problems, ensures mutual exclusion&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Sun, 23 Oct 2016 00:00:00 -0400</pubDate>
        <link>/blog/notes/os/2016/10/23/operating-system-concurrent-programming.html</link>
        <guid isPermaLink="true">/blog/notes/os/2016/10/23/operating-system-concurrent-programming.html</guid>
        
        <category>OS</category>
        
        <category>ECE344</category>
        
        <category>mutex</category>
        
        <category>synchronization</category>
        
        
        <category>Blog</category>
        
        <category>Notes</category>
        
        <category>OS</category>
        
      </item>
    
      <item>
        <title>Operating System - Basics</title>
        <description>&lt;h2&gt;Content&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Basics of OS&lt;/li&gt;
&lt;li&gt;OS Design&lt;/li&gt;
&lt;li&gt;Hardware&lt;/li&gt;
&lt;li&gt;OS-Related Hardware&lt;/li&gt;
&lt;/ol&gt;

&lt;!--more--&gt;

&lt;hr&gt;

&lt;h2&gt;Basics of OS&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Layer of &lt;code&gt;software&lt;/code&gt; between &lt;code&gt;hardware &amp;amp; applications&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Application dedicated to a single task; OS serves all applications&lt;/li&gt;
&lt;li&gt;Also called &lt;code&gt;systems software&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;&lt;strong&gt;What OS does&lt;/strong&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Manage H/W resources

&lt;ul&gt;
&lt;li&gt;Allows programs to interact with H/W

&lt;ul&gt;
&lt;li&gt;CPU, memory, disk, graphics card, co-processors, ...&lt;/li&gt;
&lt;li&gt;Simpler interface to devices

&lt;ul&gt;
&lt;li&gt;e.g. access disk as files&lt;/li&gt;
&lt;li&gt;&lt;em&gt;If NOT, apps have to be written to specific H/W devices directly -&amp;gt; deal with all the specific H/W stuffs -&amp;gt; not compatible to another manufacturer&amp;#39;s device&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Allows running many programs at the same time

&lt;ul&gt;
&lt;li&gt;Programs share CPU, memory&lt;/li&gt;
&lt;li&gt;Isolates apps from each other

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;If NOT, then memory corruption a problem&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Isolates itself from apps

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;If NOT, then OS has to compromise for apps; apps may corrupt OS and no isolations provided to them&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr&gt;

&lt;h2&gt;OS Design&lt;/h2&gt;

&lt;h3&gt;Key Ideas&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;How does OS allow running many programs?

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Virtualization&lt;/code&gt; - programs share resources securely&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;How does OS allow programs to interact with H/W?

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Abstraction&lt;/code&gt; for H/W&lt;/li&gt;
&lt;li&gt;Implemented via &lt;code&gt;System calls&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;&lt;strong&gt;Virtualization&lt;/strong&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Programs think:

&lt;ul&gt;
&lt;li&gt;They are running on their own machine (but only one physical machine!)&lt;/li&gt;
&lt;li&gt;They have full access to CPU, memory, disk&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Benefits

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Resource isolation&lt;/code&gt; (an ideal virtual machine)

&lt;ul&gt;
&lt;li&gt;Program cannot accidentally overwrite others&amp;#39; memory or files&lt;/li&gt;
&lt;li&gt;Ideally, if a program uses too much memory, only its performance degrades&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Improves &lt;strong&gt;portablity&lt;/strong&gt; of programs&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;An ideal virtual machine ~ physical machine, i.e. programs won&amp;#39;t affect each other&lt;/li&gt;
&lt;li&gt;Implementation

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Processor -&amp;gt; Threads&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Memory -&amp;gt; Virtual Memory&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;Contiguous &amp;amp; private memory&lt;/li&gt;
&lt;li&gt;Illusion of access to large amount of memory&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Disk -&amp;gt; Files&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Network -&amp;gt; Sockets&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;Hides details of network protocols &amp;amp; layers&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;&lt;strong&gt;Abstraction&lt;/strong&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Eases programming, improves &lt;strong&gt;portability&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;Concurrency&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Thread abstraction&lt;/code&gt; allows program to concurrently perform several tasks

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Race condition?&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;System Calls&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Program request H/W access via &lt;code&gt;system calls&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;OS API&lt;/code&gt;: a set of system calls&lt;/li&gt;
&lt;li&gt;Requires control transfer from &lt;code&gt;user space&lt;/code&gt; to &lt;code&gt;kernel space&lt;/code&gt; via &lt;code&gt;interrupts&lt;/code&gt; or &lt;code&gt;traps&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;e.g.

&lt;ul&gt;
&lt;li&gt;Create/destroy process (&lt;em&gt;process-related system calls&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;Allocate/deallocate memory from system (&lt;em&gt;memory-related system calls&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;Read/write a file&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Ex.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;    Program | Library
    -----------------
        OS Kernel                           # program read() 
    -----------------                       # -&amp;gt; library generates trap 
           H/W                              # -&amp;gt; trap invokes kernel 
                                            # -&amp;gt; kernel accesses disk 
    Program (read) -&amp;gt; library               # -&amp;gt; kernel returns results to program
    ------------------(trap)--^----                 
        OS Kernel        |    |
    ---------------------v-(result)
                H/W             
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;OS Interface&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;OS interface&lt;/code&gt; to H/W = set of &lt;strong&gt;system calls&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;VM interface&lt;/code&gt; to H/W = subset of physical machine interface + OS interface&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;    * Application Layer

    * OS Interface 
(system calls: thread_create(), read(), write(), thread_join(), ...)

    (when program needs access to devices)
------------virtual machine interface--------
    * OS Kernel                             |
(thread scheduler, memory mgmt,             |
device mgmt, file sys, network comm,        |
protection, process mgmt, security, ...)    |   (when program runs most instructions)
                                            |
-----------physical machine interface---------virtual/physical machine interface-------
                                                    (user mode interface)
    * H/W Layer
(network, CPU, memory, printer, video card, monitor, disk, ...)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;hr&gt;

&lt;h2&gt;Hardware&lt;/h2&gt;

&lt;h3&gt;&lt;strong&gt;Processor (CPU)&lt;/strong&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;CPU executes a set of instructions&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Fetch&lt;/code&gt; - &lt;code&gt;Decode&lt;/code&gt; - &lt;code&gt;Execute&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;PC = &amp;lt;start address&amp;gt;;
while (halt flag not set) {
    IR = memory[PC];
    PC++;
    execute(IR);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Anatomy of a CPU:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Program Counter (PC)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Instruction Register (IR)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;General Registers&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Stack Pointer (SP)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Status Register (SR)&lt;/code&gt; or &lt;code&gt;Processor Status Word&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;&lt;strong&gt;Memory&lt;/strong&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Memory (DRAM) provides storage for &lt;code&gt;code&lt;/code&gt; &amp;amp; &lt;code&gt;data&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Abstraction

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Write(addr, val)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;val = Read(addr)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Anatomy of memory

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Data sections&lt;/code&gt;: global vars&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Stack&lt;/code&gt;: local vars, parameters, return values&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Heap&lt;/code&gt;: dynamic vars&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;&lt;strong&gt;I/O Devices&lt;/strong&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Runs &lt;strong&gt;concurrently&lt;/strong&gt; with &lt;code&gt;CPU&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Connected to &lt;strong&gt;device-specific controllers&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Buses&lt;/code&gt; connect &lt;code&gt;CPU&lt;/code&gt; to &lt;code&gt;memory&lt;/code&gt; &amp;amp; &lt;code&gt;controllers&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Each &lt;code&gt;controller&lt;/code&gt; owns a range of &lt;code&gt;bus addresses&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;CPU&lt;/code&gt; sends messgage to address using:

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Special I/O instructions&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Memory-mapped I/O&lt;/code&gt;: 

&lt;ul&gt;
&lt;li&gt;Memory locations mapped to device registers&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Communication model

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Send(addr, val)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;val = Receive(addr)&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;CPU&lt;/code&gt; polling the addr for val &amp;amp; read the data with another address&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Similar to memory abstraction?

&lt;ul&gt;
&lt;li&gt;But data may &lt;em&gt;never arrive&lt;/em&gt;, &lt;em&gt;get corrupted&lt;/em&gt;, or &lt;em&gt;arrive out-of-order&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Polling&lt;/code&gt; frequency?

&lt;ul&gt;
&lt;li&gt;Too high -&amp;gt; waste CPU&lt;/li&gt;
&lt;li&gt;Too low -&amp;gt; data loss or delay&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;&lt;strong&gt;Interrupts&lt;/strong&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Polling&lt;/code&gt; not efficient -&amp;gt; let devices send &lt;code&gt;interrupts&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;CPU&lt;/code&gt; has &lt;code&gt;interrupt request flag&lt;/code&gt; to be set by devices&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Requires support from H/W &amp;amp; S/W&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Processor execution with &lt;code&gt;interrupts&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;1. (H/W) When interrupt flag set:
    H/W saves PC
    Set PC to predetermined address
    The address contains 'interrupt handler'
2. (S/W) When H/W executes next instruction:
    Save CPU registers
    Run interrupt handler
    Restore CPU registers
3. (S/W) Handler runs 'return from interrupt' instruction:
    Set PC to original next instruction
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;PC = &amp;lt;start address&amp;gt;;
while (halt flag not set) {
    IR = memory[PC];
    PC++;
    execute(IR);
    if (InterruptRequest) {
        H/W save PC, SP, SR in stack; // not all states, only those necessary to be returned from handler
        PC = memory[0]; // where interrupt handler resides
    }
}
Interrupt_handler(){
    save_processor_state(); // gets to choose essential states to save
    handle_interrupt();
    restore_processor_state();
    return;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr&gt;

&lt;h2&gt;OS-Related Hardware&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;OS is S/W, when other apps are running, it is not. How does OS manage resources?

&lt;ul&gt;
&lt;li&gt;Requires H/W support to implement virtualization &amp;amp; abstraction &lt;strong&gt;efficiently&lt;/strong&gt; &amp;amp; &lt;strong&gt;securely&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Efficient&lt;/strong&gt; because no need to provide interpreter for every single instruction that provides H/W &lt;code&gt;abstraction&lt;/code&gt; &amp;amp; &lt;code&gt;virtualization&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Secure&lt;/strong&gt; because &lt;code&gt;CPU modes&lt;/code&gt;, &lt;code&gt;MMU&lt;/code&gt;, &amp;amp; &lt;code&gt;traps&lt;/code&gt; ensure no corruption between programs&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;&lt;strong&gt;CPU Modes&lt;/strong&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;2 CPU Modes:

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Kernel mode&lt;/code&gt; - OS

&lt;ul&gt;
&lt;li&gt;Every instruction can be executed&lt;br&gt;
e.g. access disk &amp;amp; timer, controll interrupts, setting CPU mode&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;User mode&lt;/code&gt; - Programs

&lt;ul&gt;
&lt;li&gt;A subset of instructions can be executed&lt;br&gt;
e.g. &lt;code&gt;add&lt;/code&gt;, &lt;code&gt;sub&lt;/code&gt;, &lt;code&gt;push&lt;/code&gt;, &lt;code&gt;pop&lt;/code&gt;, etc.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Current mode kept in &lt;code&gt;status register&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Devices mapped to kernel memory&lt;/li&gt;
&lt;li&gt;OS is priviledged &amp;amp; trusted program; correct system operation depend on correct OS design &amp;amp; implementation instead of user programs&lt;/li&gt;
&lt;li&gt;Enables &lt;code&gt;memory isolation&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Memories &amp;amp; registers can only be changed in &lt;code&gt;privileged mode&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;&lt;strong&gt;Memory Management&lt;/strong&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Memory Management Unit (MMU)&lt;/code&gt;

&lt;ol&gt;
&lt;li&gt;Programs use &lt;code&gt;virtual memory addresses&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;CPU&lt;/code&gt; sends &lt;code&gt;virtual addresses&lt;/code&gt; to &lt;code&gt;MMU&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;MMU&lt;/code&gt; translates them to &lt;code&gt;physical addresses&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;MMU&lt;/code&gt; accesses &lt;code&gt;physical addresses&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;Anatomy of a simple MMU

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Base register&lt;/code&gt;
&lt;code&gt;Phys addr = Virt addr + Base reg&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Limit register&lt;/code&gt;
&lt;code&gt;Virt addr &amp;lt; Limit reg&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Enables &lt;code&gt;memory virtualization&lt;/code&gt; &amp;amp; &lt;code&gt;memory isolation&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Memory virtualization&lt;/code&gt;: Each program has access to a large amount of contiguous, private memory, starting at address 0&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Memory isolation&lt;/code&gt;: Ensures OS &amp;amp; other programs are located in different physical memory, and they cannot step on each other (memory access permission check)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;&lt;strong&gt;Trap&lt;/strong&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;For programs to switch to &lt;code&gt;kernel mode&lt;/code&gt; and run &lt;code&gt;OS code&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Programs cannot call &lt;code&gt;OS code&lt;/code&gt; directly because &lt;code&gt;MMU&lt;/code&gt; isolates &lt;code&gt;OS code&lt;/code&gt; &amp;amp; program not in &lt;code&gt;kernel mode&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Provides a secure way to enter the kernel&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Similar to handling &lt;code&gt;interrupts&lt;/code&gt;&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;# (H/W) On trap:
    Switch to kernel mode
    Run OS handler code at well-defined location
# (S/W) OS handler code:
    Save processor state
    Runs kernel functions to access H/W
    Restore processor state
    Return to user code, switch to user mode
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;=&amp;gt; &lt;strong&gt;atomic&lt;/strong&gt; to avoid &lt;code&gt;user code&lt;/code&gt; running in &lt;code&gt;kernal mode&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Unix system calls&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Process related&lt;br&gt;
e.g. fork, exec, wait, exit, kill, signal&lt;/li&gt;
&lt;li&gt;File related&lt;br&gt;
e.g. open, read, write, close, link, unlink, chdir&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Invoking system call&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;read(file, buff, n) { // library code
    ...
    lw v0, SYS_read // load syscall number into v0 reg

    syscall // trap
    ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;Traps&lt;/code&gt;, &lt;code&gt;interrupts&lt;/code&gt;, &lt;code&gt;exceptions&lt;/code&gt;&lt;/p&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th style=&quot;text-align: left&quot;&gt;Interrupt&lt;/th&gt;
&lt;th style=&quot;text-align: left&quot;&gt;Trap&lt;/th&gt;
&lt;th style=&quot;text-align: left&quot;&gt;Exception&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Cause&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;H/W external to CPU&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Explicit intruction&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Instruction failure&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Effect&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Program unaware of interrupt handling (async)&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Similar to program invoked function, function returns data (sync)&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Abnormal control flow&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Timeliness&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Needs to respond quickly&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;Program suspended, OS can take time&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;OS can take time&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr&gt;

&lt;h2&gt;&lt;strong&gt;Quick Questions&lt;/strong&gt;&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;How does OS manage H/W?

&lt;ul&gt;
&lt;li&gt;Abstraction &amp;amp; virtualization&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;OS is software, when other applications are running, it is not running, so how can it do its work?

&lt;ul&gt;
&lt;li&gt;H/W support e.g. CPU modes, MMU, traps&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Why can’t applications corrupt other applications or the OS?

&lt;ul&gt;
&lt;li&gt;MMU helps&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Why can’t applications directly access h/w?

&lt;ul&gt;
&lt;li&gt;I/O devices are mapped to kernel memory, so no access allowed by MMU; or, I/O intructions are priviledged&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Why is the OS not a normal program?

&lt;ul&gt;
&lt;li&gt;Entered from different locations (system calls and interrupts) in response to external events&lt;/li&gt;
&lt;li&gt;It does not have a single thread of control, it can be invoked simultaneously by two different events (e.g. system call &amp;amp; interrupt)&lt;/li&gt;
&lt;li&gt;It is not supposed to terminate&lt;/li&gt;
&lt;li&gt;Can execute any instruction in the machine&lt;/li&gt;
&lt;li&gt;Has access to the entire memory on the machine&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;What if a program tries to cheat?

&lt;ol&gt;
&lt;li&gt;What happens if it issues a privileged instruction directly? 

&lt;ul&gt;
&lt;li&gt;Attempting execution of privileged instruction in user mode causes trap, so kernel gets control. Normally, kernel will kill program.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;What if a running thread doesn’t make a system call to the OS and hence hogs the CPU?

&lt;ul&gt;
&lt;li&gt;OS must register a future timer interrupt before it hands control of the CPU over to a thread; when the timer interrupt goes off, the OS gets control&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;What stops the running program from disabling an interrupt?

&lt;ul&gt;
&lt;li&gt;It is a priviledges instruction&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;What stops a program from modifying the OS so that the OS runs user code?

&lt;ul&gt;
&lt;li&gt;Program cannot even see OS code due to memory virtualization&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;What stops a program from changing the MMU registers?

&lt;ul&gt;
&lt;li&gt;It is a priviledges instruction&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;How does the OS solve these problems:

&lt;ol&gt;
&lt;li&gt;Time sharing the CPU among programs?

&lt;ul&gt;
&lt;li&gt;Timer interrupts&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Space sharing memory among programs?

&lt;ul&gt;
&lt;li&gt;MMU&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Protection of programs from each other?

&lt;ul&gt;
&lt;li&gt;1. &amp;amp; 2.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Protection of hardware/devices?

&lt;ul&gt;
&lt;li&gt;I/O devices are mapped to kernel memory, so no access allowed by MMU; or, I/O intructions are priviledged&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Protection of the OS itself?

&lt;ul&gt;
&lt;li&gt;MMU isolates OS code&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;Does library code (executing in user mode) provide isolation and abstraction?

&lt;ul&gt;
&lt;li&gt;Provides abstraction but not isolation. Programs can jump to any instruction in library code, overwrite library code/data, thus bypassing any isolation that library code may try to provide.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Does a virtual machine monitor (VMM) such as VMware provide isolation and abstraction?

&lt;ul&gt;
&lt;li&gt;A VMM is a system program, similar to an OS, that allows multiple OSs to run simultaneously on a single physical machine&lt;/li&gt;
&lt;li&gt;It provides isolation, but the same abstraction as a physical machine (each OS thinks it is running on physical hardware), thus providing no additional abstraction than the physical machine.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Why can’t user code execute some arbitrary code of its choosing in kernel mode?

&lt;ul&gt;
&lt;li&gt;User code wants to execute some code in kernel mode, so what can it do?

&lt;ol&gt;
&lt;li&gt;Write instructions into kernel image - can’t do that due to memory protection.&lt;/li&gt;
&lt;li&gt;Transfer control to arbitrary places in kernel image to skip checks - can’t do this due to memory protection, and control can only be transferred via TRAP to well known kernel entry locations.&lt;/li&gt;
&lt;li&gt;Execute privileged instructions - can’t do this in user mode.&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;What is the minimum number of privileged instructions that h/w must implement so that the OS can work correctly?

&lt;ul&gt;
&lt;li&gt;With memory mapped IO, you can hide all device accesses with memory protection. So programming the MMU (i.e., modify MMU registers) should be privileged. &lt;/li&gt;
&lt;li&gt;Also, returning from a trap (e.g., iret instruction) should ensure that we cannot switch from user to kernel mode and run arbitrary kernel code. For example, on x86, a return from trap is guaranteed to execute code with the same or lower privilege level.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Similarities &amp;amp; differences between &lt;code&gt;OS&lt;/code&gt; &amp;amp; &lt;code&gt;web browsers&lt;/code&gt;?

&lt;ul&gt;
&lt;li&gt;Similarities

&lt;ul&gt;
&lt;li&gt;Both run multiple applications (processes &amp;amp; web applications)&lt;/li&gt;
&lt;li&gt;Both need to isolate/protect different applications&lt;/li&gt;
&lt;li&gt;Both need to ensure their own code is safe from application code&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Differences

&lt;ul&gt;
&lt;li&gt;OS uses H/W protection to protect OS and application code; browsers normally use S/W/language-level protection&lt;/li&gt;
&lt;li&gt;OS has direct access to H/W; browsers need to use OS to access&lt;/li&gt;
&lt;li&gt;OS usually runs local code; the main function of browsers is to run remote code and display remote data&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Why can&amp;#39;t OS code be shared like library codes do?

&lt;ul&gt;
&lt;li&gt;Some OS code needs to execute privileged instructions and hence will not run in user mode.&lt;/li&gt;
&lt;li&gt;The OS code may manipulate data that can be globally shared across programs (e.g., the scheduler run queue). Since libraries share code but not data, the library code would not be able to access this shared data.&lt;/li&gt;
&lt;li&gt;If the OS code is run in user mode, and it could be modified then the security guarantees provided by the OS could be compromised.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Fri, 21 Oct 2016 00:00:00 -0400</pubDate>
        <link>/blog/notes/os/2016/10/21/operating-system-basics.html</link>
        <guid isPermaLink="true">/blog/notes/os/2016/10/21/operating-system-basics.html</guid>
        
        <category>OS</category>
        
        <category>ECE344</category>
        
        
        <category>Blog</category>
        
        <category>Notes</category>
        
        <category>OS</category>
        
      </item>
    
      <item>
        <title>Divide and Conquer</title>
        <description>&lt;h2&gt;Content&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Multiplication&lt;/li&gt;
&lt;li&gt;Convex Hull&lt;/li&gt;
&lt;/ol&gt;

&lt;!--more--&gt;

&lt;hr&gt;

&lt;h1&gt;Divide &amp;amp; Conquer&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;Breaking problems into subproblems&lt;/li&gt;
&lt;li&gt;Recursively solving these subproblems&lt;/li&gt;
&lt;li&gt;Combining the answers&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;a subproblems of size n/b, combining the answers in O(n^d) time.

The k-th level of tree has a^k subproblems, each of size n/(b^k).
=&amp;gt; a^k * O(n/(b^k)^d) = O(n^d) * (a/(b^d))^k

=&amp;gt; T(n) = aT(⌈n/b⌉) + O(nd)
        = O(n^d)          if a/(b^d) &amp;lt; 1
        = O((n^d)logn)    if a/(b^d) = 1
        = O(n^(log_b(a))) if a/(b^d) &amp;gt; 1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Multiplication&lt;/h2&gt;

&lt;p&gt;Multiply 2 n-bit integers &lt;code&gt;x&lt;/code&gt;, &lt;code&gt;y&lt;/code&gt; where &lt;code&gt;n&lt;/code&gt; is a power of 2.&lt;/p&gt;

&lt;h4&gt;Steps&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Split &lt;code&gt;x&lt;/code&gt;, &lt;code&gt;y&lt;/code&gt; into halves.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;x = 2^(n/2)xl + xr&lt;/code&gt;&lt;br&gt;
&lt;code&gt;y = 2^(n/2)yl + yr&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Multiplication becomes:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;xy = (2^(n/2)xl + xr) * (2^(n/2)yl + yr) = (2^n)xlyl + 2^(n/2)(xlyr + xryl) + xryr&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Consider:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;xlyr + xryl = (xl + xr)(yl + yr) - xlyl - xryr&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Multiplication becomes 3 multiplication subproblems.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4&gt;Running Time&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;At depth k, there are &lt;code&gt;3^k&lt;/code&gt; subproblems, each of size &lt;code&gt;n/(2^k)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;3^k * O(n/(2^k)) = (3/2)^k * O(n)&lt;/code&gt; at depth k&lt;/li&gt;
&lt;li&gt;&lt;code&gt;T(n) = 3T(n/2) + O(n) = O(n^1.59)&lt;/code&gt; in total&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;Pseudocode&lt;/h4&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;Multiply(x, y):
    # Input: Positive integers x and y, in binary 
    # Output: Their product

    n = max(size of x, size of y) 
    if n = 1: 
        return xy

    xL, xR = leftmost⌈n/2⌉, rightmost⌊n/2⌋ bits of x yL, yR = leftmost⌈n/2⌉, rightmost⌊n/2⌋ bits of y

    P1 = Multiply(xL, yL)
    P2 = Multiply(xR, yR)
    P3 = Multiply(xL + xR, yL + yR)
    return P1 × 2^n + (P3 − P1 −P2) × 2^(n/2) + P2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Convex Hull&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Graham&amp;#39;s scan: &lt;code&gt;O(nlogn)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;&lt;em&gt;Divide and Conquer Convex Hull&lt;/em&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Generalization of &lt;strong&gt;MergeSort&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;Pseudocode&lt;/h4&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;# Presort points by x coordinate =&amp;gt; O(nlogn)
# Assume linked list of hull vertices

MergeHull(HA, HB):
    Compute upper &amp;amp; lower tangents for HA &amp;amp; HB
    Discard all points lying between 2 tangents
    return MergedH

Hull(S):
    If |S| &amp;lt;= 3:
        Compute convex hull by brute force # =&amp;gt; O(1)
        return H
    Else:
        Partition S into A (lowest x) &amp;amp; B (highest x) # =&amp;gt; O(n)
        HA = Hull(A)
        HB = Hull(B)
        H = MergeHull(HA, HB) # =&amp;gt; O(n)
        return H
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;=&amp;gt;  &lt;code&gt;
    T(n) = 1           if n &amp;lt;= 3
           n + 2T(n/2) otherwise
&lt;/code&gt;
=&amp;gt; &lt;code&gt;O(nlogn)&lt;/code&gt;&lt;/p&gt;

&lt;h4&gt;Computing Tangents&lt;/h4&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;# Walking procedure

LowerTangent(HA, HB):
    Init a = rightmost point of HA
    Init b = leftmost point of HB

    # Orientation test of a, b, and neighboring vertices 
    While ab not a lower tangent for HA &amp;amp; HB:
        While ab not a lower tangent for HA:
            a = a - 1 # move clockwise
        While ab not a lower tangent for HB:
            b = b + 1 # move counterclockwise
    Return ab
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;=&amp;gt; &lt;code&gt;O(|HA| + |HB|) &amp;lt;= O(|A| + |B|) = O(n)&lt;/code&gt;&lt;/p&gt;

&lt;h3&gt;&lt;em&gt;Quickhull&lt;/em&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Generalization of &lt;strong&gt;QuickSort&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;O(nlogn)&lt;/code&gt; ~ &lt;code&gt;O(n^2)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;No obvious way to convert it into randomized algorithm with &lt;code&gt;O(nlogn)&lt;/code&gt; expected running time; but still performs well&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;Idea&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Discard points not on the hull as quickly as possible&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;Steps&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;Find max &amp;amp; min x, y coordinates&lt;/li&gt;
&lt;li&gt;Draw a bounding rectangle -&amp;gt; those lying within discarded =&amp;gt; &lt;code&gt;O(n)&lt;/code&gt; by now&lt;/li&gt;
&lt;li&gt;Classify remaining points into 4 corners -&amp;gt; if no remaining, then done&lt;/li&gt;
&lt;li&gt;For each corner, find a point &lt;code&gt;c&lt;/code&gt; that lies on the hull. May choose &lt;code&gt;c&lt;/code&gt; by the most perpendicular distance.&lt;/li&gt;
&lt;li&gt;Discard those in the triangle, and split remaining points into 2 subsets (classify them by 2 orientation tests).&lt;/li&gt;
&lt;li&gt;Add the 2 corners in buckets, and recurse.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4&gt;Running Time&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Depends on how evenly the points are split&lt;br&gt;
=&amp;gt;  &lt;code&gt;
T(n) = 1             if n = 1
       T(n1) + T(n2) where n1 + n2 &amp;lt;= n
&lt;/code&gt;&lt;br&gt;
=&amp;gt; &lt;code&gt;O(nlogn)&lt;/code&gt; if evenly distributed (&lt;code&gt;n1 ~= n2&lt;/code&gt;; &lt;code&gt;max(n1, n2) &amp;lt;= a * n&lt;/code&gt; for some constant &lt;code&gt;a &amp;lt; 1&lt;/code&gt;)&lt;br&gt;
=&amp;gt; &lt;code&gt;O(n^2)&lt;/code&gt; otherwise&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;&lt;em&gt;Gift Wrapping and Jarvis&amp;#39;s March&lt;/em&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Variation of &lt;strong&gt;SelectionSort&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;O(n^2)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;Steps&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;Find any point on convex hull, e.g. lowest point&lt;/li&gt;
&lt;li&gt;Say start with &lt;code&gt;p(0) = (Inf, 0)&lt;/code&gt;, &lt;code&gt;p(1) = lowest point&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Assume &lt;code&gt;p(k)&lt;/code&gt; &amp;amp; &lt;code&gt;p(k-1)&lt;/code&gt; were the last 2 points added, find the next one &lt;code&gt;q&lt;/code&gt; s.t. &lt;code&gt;angle[p(k-1), p(k), q]&lt;/code&gt; is maximized =&amp;gt; &lt;code&gt;O(n)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Repeat &lt;code&gt;h&lt;/code&gt; times, return back to starting point&lt;/li&gt;
&lt;/ol&gt;

&lt;h4&gt;Running Time&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;O(nh)&lt;/code&gt;, where n is the input size, h is the output size&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;If h = o(logn), then faster than Graham&amp;#39;s!&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;&lt;em&gt;Chan&amp;#39;s Algorithm&lt;/em&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Combination of &lt;strong&gt;Graham&amp;#39;s scan&lt;/strong&gt; &amp;amp; &lt;strong&gt;Jarvis&amp;#39;s march&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Aims to be &lt;code&gt;O(nlogh)&lt;/code&gt; (lower bound)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;Steps&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;Partition points into groups of equal size &lt;code&gt;m&lt;/code&gt; points, total &lt;code&gt;r&lt;/code&gt; groups&lt;/li&gt;
&lt;li&gt;For each group, compute its hull using &lt;strong&gt;Graham&amp;#39;s scan&lt;/strong&gt; =&amp;gt; total &lt;code&gt;O(rmlogm)&lt;/code&gt; = &lt;code&gt;O(nlogm)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Run &lt;strong&gt;Jarvis&amp;#39;s march&lt;/strong&gt; on the groups. Computing tangent between a point &amp;amp; a convex &lt;code&gt;m&lt;/code&gt; takes &lt;code&gt;O(logm)&lt;/code&gt; time (binary search)&lt;br&gt;
=&amp;gt; total &lt;code&gt;O(rlogm)&lt;/code&gt; for &lt;code&gt;r&lt;/code&gt; groups&lt;br&gt;
=&amp;gt; &lt;code&gt;h&lt;/code&gt; steps of Jarvis&amp;#39;s march, total &lt;code&gt;O(hrlogm)&lt;/code&gt; time&lt;/li&gt;
&lt;li&gt;Combining, we get &lt;code&gt;O((n + hn/m) logm)&lt;/code&gt; time&lt;/li&gt;
&lt;li&gt;If set &lt;code&gt;m = h&lt;/code&gt;, running time &lt;code&gt;O(nlogh)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4&gt;Tricks&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;How do we know what &lt;code&gt;m&lt;/code&gt; is if we don&amp;#39;t know &lt;code&gt;h&lt;/code&gt; in advance?

&lt;ul&gt;
&lt;li&gt;Guess the value: try &lt;code&gt;m = 1, 2, ...&lt;/code&gt;, until &lt;code&gt;m &amp;gt;= h&lt;/code&gt; =&amp;gt; too long!&lt;/li&gt;
&lt;li&gt;Binary search =&amp;gt; but if &lt;code&gt;m = n/2&lt;/code&gt;, stuck to &lt;code&gt;O(nlogn)&lt;/code&gt; time&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Doubling search&lt;/strong&gt;:
Start with small &lt;code&gt;m&lt;/code&gt; and increase it rapidly (say, squaring it) =&amp;gt; &lt;code&gt;O(nlogh)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;Pseudocode&lt;/h4&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;PartialHull(P, m):

    Let r = ceil(n/m)
    Partition P into disjoint subsets P(1),P(2),... P(r), each of size at most m

    For i = 1 to r do:
        Compute Hull(P(i)) using Graham's scan
        Store the vertices in an ordered array

    Let p0 = (-Inf, 0)
    Let p1 be the bottommost point of P

    For k = 1 to m do: # =&amp;gt; O(hrlogm) where we assume h = m
        For i = 1 to r do: # =&amp;gt; O(rlogm)
            Compute point q in P(i) that maximizes the angle[p(k-1), p(k), q] # =&amp;gt; O(logm)
        Let p(k+1) be the point q in q(1),q(2),...q(r) that maximizes the angle[p(k-1), p(k), q]
        If p(k+1) = p(1):
            Return {p(1), p(2), ... p(k)}

    Return &quot;m was too small, try again.&quot;

Hull(P):

    For t = 1.. do: # stop when 2^2^t &amp;gt;= h, or t = ceil(lglgh)
        Let m = min(2^(2^t), n)
        Let L = PartialHull(P, m)
        If L != &quot;try again&quot;:
            Return L

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;Running Time&lt;/h4&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;The t-th iteration takes O(nlog2^2^t) = O(n*2^t) time
Sum(t = 1..lglgh) n*2^t =
    n * Sum(t = 1..lglgh) 2^t &amp;lt;= 
    n * 2^(1+lglgh) = 
    2nlgh = 
    O(nlogh)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.cs.wustl.edu/%7Epless/506/l3.html&quot;&gt;http://www.cs.wustl.edu/~pless/506/l3.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Wed, 12 Oct 2016 00:00:00 -0400</pubDate>
        <link>/blog/notes/algorithm/2016/10/12/divide-and-conquer.html</link>
        <guid isPermaLink="true">/blog/notes/algorithm/2016/10/12/divide-and-conquer.html</guid>
        
        <category>convex hull</category>
        
        <category>divide and conquer</category>
        
        <category>algorithm</category>
        
        <category>CSC384</category>
        
        
        <category>Blog</category>
        
        <category>Notes</category>
        
        <category>Algorithm</category>
        
      </item>
    
  </channel>
</rss>
